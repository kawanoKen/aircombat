{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 応募用ファイルの作成手順"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでは環境構築から始めて, エージェントを作成して投稿ができるフォーマットに整理し, 実際に対戦を実行して最終的に応募用ファイルを作成するまでの流れの一例を説明する."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 事前準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### シミュレータのダウンロード"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[コンペティションサイト](https://user.competition.signate.jp/ja/competition/detail/?competition=de1556abda294254b30bdec61520f764)から`simulator_dist.zip`をダウンロードして, 作業ディレクトリに展開しておく. 部門別にダウンロード先は異なるので, 注意. オープン部門は[こちら](https://user.competition.signate.jp/ja/competition/detail/?competition=de1556abda294254b30bdec61520f764&task=58817e1148ad44828cd34018296d09b6&tab=task), ユース部門は[こちら](https://user.competition.signate.jp/ja/competition/detail/?competition=de1556abda294254b30bdec61520f764&task=ddc905b07101400b83e5a43d3e7c7b72&tab=task)のデータタブよりダウンロードする. 展開後, 以下のようなディレクトリ構造のファイル群が作成される.\n",
    "\n",
    "```bash\n",
    "simulator_dist\n",
    "├── Agents                            : 行動判断モジュールを格納したディレクトリ\n",
    "├── common                            : コンペティションで定義されている戦闘場面などの設定ファイルを格納したディレクトリ\n",
    "├── dist                              : シミュレータ本体を含めた依存ライブラリのwhlファイルを格納したディレクトリ\n",
    "├── dockerfiles                       : Dockerによる環境構築に使われるベースイメージファイルを格納したディレクトリ\n",
    "│   ├── Dockerfile.cpu                : CPU用の環境\n",
    "│   ├── Dockerfile.gpu                : GPU用の環境\n",
    "│   └── Dockerfile.macos              : MacOS用の環境\n",
    "├── docs                              : 説明資料を格納したディレクトリ\n",
    "│   └── html\n",
    "│       └── core\n",
    "│           └── index.html            : 説明資料のトップページ\n",
    "├── figs                              : 説明図などを格納したディレクトリ\n",
    "├── simulator                         : シミュレータ本体\n",
    "├── src                               : 対戦などを行うためのモジュールを実装したプログラム\n",
    "├── docker-compose.yml                : 仮想環境を構築するための定義ファイル\n",
    "├── make_agent.ipynb                  : エージェントを作成するための簡単な手順を示したノートブック\n",
    "├── README.md                         : シミュレータなどに関する解説ドキュメント\n",
    "├── replay.py                         : 戦闘シーンを動画として作成するプログラム\n",
    "└── validate.py                       : エージェント同士の対戦を実行するプログラム\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ドキュメントリンクの有効化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "必要に応じて`tutorial/docs`以下に, 配布されたシミュレータの`simulator_dist/docs`にあるドキュメントをすべてコピーしたうえで, `tutorial/docs/html`のドキュメントリンクを有効化しておく. 例えば, Pythonを使って\n",
    "\n",
    "```bash\n",
    "$ python -m http.server 5500\n",
    "```\n",
    "としてサーバを起動できる. VSCodeを使用している場合は, 拡張機能[LiveServer](https://marketplace.visualstudio.com/items?itemName=ritwickdey.LiveServer)をインストールし, このファイルがあるディレクトリを開いた状態で画面右下の「Go Live」アイコンをクリックすれば自動的に5500番ポートにサーバが起動する. すると, このノートブックに記載されているリンクが有効になり閲覧することができるようになる."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 環境構築"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`simulator_dist/README.md`の「環境構築」項目にある通りに好きな方法で構築する."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Dockerによる構築(推奨)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`simulator_dist/docker-compose.yml`の`dev1`-`build`->`dockerfile`でOS別に`dockerfiles`のDockerfileを選択することで各自のOSに合わせて環境構築ができる. コンペティションの評価環境で実行する場合は, `simulator_dist/docker-compose.yml`を下記のように編集する.\n",
    "\n",
    "```yaml\n",
    "services:\n",
    "  dev1:\n",
    "    build:\n",
    "      context: .\n",
    "      dockerfile: dockerfiles/Dockerfile.cpu\n",
    "    container_name: atla4\n",
    "    ports:\n",
    "      - \"8080:8080\"\n",
    "    volumes:\n",
    "      - .:/workspace\n",
    "    tty: true\n",
    "```\n",
    "\n",
    "そして, 以下のコマンドを実行することで立ち上げる.\n",
    "\n",
    "```bash\n",
    "$ docker compose up -d\n",
    "...\n",
    "```\n",
    "そして, 以下のコマンドでコンテナの中に入り, 分析や開発を行う.\n",
    "\n",
    "```bash\n",
    "$ docker exec -it atla4 bash\n",
    "...\n",
    "```\n",
    "\n",
    "`simulator_dist/README.md`にあるように例えばDev Container拡張機能を導入済みのVSCodeで立ち上げたコンテナに入り, 動作確認などを行う.\n",
    "\n",
    "```bash\n",
    "$ cd /path/to/workspace\n",
    "$ python validate.py --visualize 1\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPUを使う場合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ホスト側にCUDA環境に対応したGPUがある場合, CUDA環境に対応したイメージからコンテナを構築可能. 例えば`simulator_dist/docker-compose.yml`を以下のように編集しておく.\n",
    "\n",
    "```yaml\n",
    "services:\n",
    "  dev1:\n",
    "    build:\n",
    "      context: .\n",
    "      dockerfile: dockerfiles/Dockerfile.gpu\n",
    "    deploy:\n",
    "      resources:\n",
    "        reservations:\n",
    "          devices:\n",
    "            - driver: nvidia\n",
    "              count: 1\n",
    "              capabilities: [gpu]\n",
    "    container_name: atla4\n",
    "    ports:\n",
    "      - \"8080:8080\"\n",
    "    volumes:\n",
    "      - .:/workspace\n",
    "    tty: true\n",
    "```\n",
    "\n",
    "実際にGPUがコンテナ内で有効になっているかどうかは以下のコマンドで確認できる.\n",
    "\n",
    "```bash\n",
    "# コンテナに入った後\n",
    "$ python -c \"import torch; print(torch.cuda.is_available())\"\n",
    "True\n",
    "$ python -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\"\n",
    "...{GPUデバイスのリスト}...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注意点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dockerで構築する場合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 場合によっては`libPython3.10`が導入されていない状態でコンテナが立ち上がってしまう可能性がある. シミュレータを動かしたときに`ImportError: libpython3.10.so.1.0: cannot open shared object file: No such file or directory`のようなエラーが出る場合は`libPython3.10`をあらかじめインストールしておくこと.\n",
    "  - 現時点ではDockerfileでlibPython3.10がインストールされるように修正してある(例えば`simualtor_dist/dockerfiles/Dockerfile.cpu`の18行目参照).\n",
    "- VNCが不要であれば, Dockerfileで対応する部分(例えば`simualtor_dist/dockerfiles/Dockerfile.cpu`の21行目～25行目)をコメントアウトなどしておくことでイメージ作成が早くなる.\n",
    "  - `simulator_dist/README.md`にあるようにVSCodeでコンテナにアタッチしてVSCodeで実行することで動画付きで実行は可能.\n",
    "    - ホスト側とディスプレイ連携ができているか確認しておく($DISPLAY環境変数の確認, テスト用のX11アプリ(例: xeyes や xclock)を使うなど).\n",
    "    - 連携できていない場合はXサーバーを別途インストールしておく.\n",
    "  - `simulator_dist/README.md`にあるようにxvfbにより, 動画として保存しておいて後で確認ということも可能.\n",
    "  \n",
    "  ```bash\n",
    "  $ python validate.py --visualize 0 --replay 1\n",
    "  ...\n",
    "  $ xvfb-run python replay.py\n",
    "  ...\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ローカル環境で構築する場合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `simulator_dist/dist`以下にシミュレータを含んだ必要なライブラリに対応したwhlファイルがOS別に提供されているが, Python3.10の環境下でビルドされているため, それ以外のPythonの環境ではシミュレータが動かない.\n",
    "  - インストールする場合はvenvなどでPython3.10の環境を作り, そこでインストールするなどして対応すること.\n",
    "- `simulator_dist/README.md`にある通り, 必要なライブラリをあらかじめインストールしておくこと.\n",
    "\n",
    "  ```plaintext\n",
    "  torch==2.7.0, !=2.0.1\n",
    "  tensorflow==2.13.0\n",
    "  pandas==2.1.4\n",
    "  scikit-learn==1.6.1\n",
    "  lightgbm==4.5.0\n",
    "  timeout-decorator==0.5.0\n",
    "  opencv-python-headless==4.11.0.86\n",
    "  ```\n",
    "\n",
    "- ソースからビルドする場合(`simulator_dist/simulator/install_all.py`により行う場合)は時間がかかる.\n",
    "  - 自身でカスタマイズしたい場合など\n",
    "  - MacOSの場合はCMakeのバージョンは3.30未満のものを使用すること. 詳細は`simulator_dist/README.md`を参照.\n",
    "\n",
    "- GPUが有効になっているかどうかは`nvidia-smi`コマンドやDockerの場合と同様に以下のコマンドで確認できる.\n",
    "\n",
    "  ```bash\n",
    "  # コンテナに入った後\n",
    "  $ python -c \"import torch; print(torch.cuda.is_available())\"\n",
    "  True\n",
    "  $ python -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\"\n",
    "  ...{GPUデバイスのリスト}...\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### その他"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Google Colabで構築する場合, 提供されている`simulator_dist/dist/linux`のwhlによってインストールしてもPythonバージョンが合わないためシミュレータが動かない.\n",
    "  - 現在のGoogle ColabのPythonのバージョンは3.11なのでGoogle Colabの中で直接ソースからビルドするか, Pythonのバージョンを合わせたうえでビルドしたwhlファイルによってインストールするなどの方法が考えられる."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## エージェントの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基本的には`simulator_dist/make_agent.ipynb`などに従うが, observationを作成する`makeObs`メソッドやその型(観測空間)を定義する`observation_space`メソッド, 行動空間を定義する`action_space`メソッドの作成の仕方についていくつか注意点がある."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### `makeObs`メソッドと`observation_space`メソッドの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "actionを生成するためのobservationを作成する`makeObs`メソッドを実装する.\n",
    "\n",
    "- 強化学習を実装したい場合は基本的には`makeObs`メソッドで返る値は`dict`とすればよい(policyモデルに渡す想定).\n",
    "  - `observation_space`メソッドで`shape`を定義する必要がある. あらかじめどのようなobservationを作成するかを設計したうえで定義する.\n",
    "  - 対戦ログとしてobservationを取得するにはjson形式で保存できることが前提であるが, 今回の場合は`numpy.ndarray`は自動的に`list`に変換される.\n",
    "  - その他の型を返す場合はデフォルトでjson形式で保存できるような処理を挟む必要がある(`observation_space`メソッドとの整合も考慮).\n",
    "  - 特にログが欲しくない場合はそのままでよい(保存に失敗した場合, ログは勝敗結果と自分の陣営の色のみの情報になるが対戦結果自体はリーダーボードに反映される).\n",
    "- 行動判断モデルとして特に機械学習モデルを使用しないアルゴリズムを実装している場合は保存しておきたい情報をjson形式で保存できるように処理したものを返せばよい.\n",
    "  - そもそもログが必要ないなら適当に`0`などの値を返しておく.\n",
    "\n",
    "観測可能な主な情報は以下の通り.\n",
    "\n",
    "1. 自分と味方の機体諸元(位置, 速度, 姿勢, 角速度, 残弾数)\n",
    "1. 自分と味方の誘導弾諸元(位置, 速度, 目標ID, 誘導状態)\n",
    "1. 相手の機体諸元(位置と速度のみ)\n",
    "1. 相手の誘導弾諸元(方向のみ)\n",
    "1. 戦闘開始からの経過時間\n",
    "\n",
    "詳細は[「第4回空戦AIチャレンジ向けチュートリアル/Agent が入出力 observables と commands の形式#Agent が受け取ることのできる observables」](http://localhost:5500/docs/html/core/a198024.html#section_r7_contest_agent_observables)を参照されたい. 観測情報は階層構造になっていることに注目して例えば彼機の航跡は以下のような形で取得する.\n",
    "\n",
    "```Python\n",
    "parent.observables.at_p(\"/sensor/track\")\n",
    "```\n",
    "\n",
    "以下では例として'common'をkeyとした残り時間, 'parent'をkeyとした自機の位置ベクトルと速度ベクトル, 'enemy'をkeyとした検知している彼機の位置ベクトルと速度ベクトル, 'friend_missile'をkeyとした自機の誘導弾の位置ベクトルと速度ベクトル, 'enemy_missile'をkeyとしたmwsで検知している2次元航跡データとしたdictを生成する.\n",
    "\n",
    "Blue側でもRed側でも同じになるように, 自機座標系でないベクトル量は陣営座標系(自陣営の進行方向が+x方向となるようにz軸まわりに回転させ, 防衛ライン中央が原点となるように平行移動させた座標系)で表現する.\n",
    "\n",
    "その他, observation_maskとaction_maskも定義している. observation_maskはuse_observation_maskをtrueにしたときのみ生成される, 各要素に有効な値が入っているかどうかを表すマスク. 1が有効, 0が無効を表すものとする. action_maskはuse_action_maskをtrueにしたときのみに生成される, 各parentの各行動空間の有効な選択肢を表すマスク. 1が有効, 0が無効を表すものとする. ここではtargetのみマスクを計算し, それ以外の行動については全て有効(1)を出力する.\n",
    "\n",
    "observationはステップごとにログとして残すことが可能であるが, json形式で保存できるフォーマットである必要があるが, 前述の通りvalueを`numpy.ndarray`として定義している場合は特に気にすることはない. それ以外の場合はあらかじめPythonプリミティブの型として作成するフラグ(例えばconfigファイルで定義しておいて, インスタンス化したときに定義できるようにしておく)を定義しておいて, 適宜切り替えができるようにしておくとよい.\n",
    "\n",
    "そしてobservationの形を定義する`observation_space`メソッドを実装する. 各keyに応じて定義した通りの形を返す.\n",
    "\n",
    "`R7ContestSample`モジュールではより細かいobservationの作成方法が実装されているので, [simulator/sample/modules/R7ContestSample/R7ContestSample/R7ContestPyAgentSamle01.py](http://localhost:5500/docs/html/core/a198025.html)などを参照されたい."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ASRCAISim1.core import Agent, getValueFromJsonK, getValueFromJsonKR, getValueFromJsonKRD, MotionState, Track3D, Track2D, Time, TimeSystem, deg2rad, serialize_attr_with_type_info,AltitudeKeeper\n",
    "from BasicAgentUtility.util import TeamOrigin, sortTrack3DByDistance, sortTrack2DByAngle\n",
    "from gymnasium import spaces\n",
    "\n",
    "\n",
    "class SampleAgent(Agent):\n",
    "    ...\n",
    "    class ActionInfo:\n",
    "        #機体に対するコマンドを生成するための変数をまとめた構造体\n",
    "        def __init__(self):\n",
    "            self.dstDir=np.array([1.0,0.0,0.0]) #目標進行方向\n",
    "            self.dstAlt=10000.0 #目標高度\n",
    "            self.velRecovery=False #下限速度制限からの回復中かどうか\n",
    "            self.asThrottle=False #加減速についてスロットルでコマンドを生成するかどうか\n",
    "            self.keepVel=False #加減速について等速(dstAccel=0)としてコマンドを生成するかどうか\n",
    "            self.dstThrottle=1.0 #目標スロットル\n",
    "            self.dstV=300 #目標速度\n",
    "            self.launchFlag=False #射撃するかどうか\n",
    "            self.target=Track3D() #射撃対象\n",
    "            self.lastShotTimes={} #各Trackに対する直前の射撃時刻\n",
    "        def serialize(self, archive):\n",
    "            serialize_attr_with_type_info(archive, self\n",
    "                ,\"dstDir\"\n",
    "                ,\"dstAlt\"\n",
    "                ,\"velRecovery\"\n",
    "                ,\"asThrottle\"\n",
    "                ,\"keepVel\"\n",
    "                ,\"dstThrottle\"\n",
    "                ,\"dstV\"\n",
    "                ,\"launchFlag\"\n",
    "                ,\"target\"\n",
    "                ,\"lastShotTimes\"\n",
    "            )\n",
    "        _allow_cereal_serialization_in_cpp = True\n",
    "        def save(self, archive):\n",
    "            self.serialize(archive)\n",
    "        @classmethod\n",
    "        def static_load(cls, archive):\n",
    "            ret=cls()\n",
    "            ret.serialize(archive)\n",
    "            return ret\n",
    "\n",
    "\n",
    "    def initialize(self):\n",
    "        super().initialize()\n",
    "        self.own = self.getTeam()\n",
    "        self.common_dim = 1\n",
    "        self.maxParentNum=getValueFromJsonK(self.modelConfig,\"maxParentNum\")\n",
    "        self.maxFriendNum=getValueFromJsonK(self.modelConfig,\"maxFriendNum\")\n",
    "        self.maxEnemyNum=getValueFromJsonK(self.modelConfig,\"maxEnemyNum\")\n",
    "        self.maxFriendMissileNum=getValueFromJsonK(self.modelConfig,\"maxFriendMissileNum\")\n",
    "        self.maxEnemyMissileNum=getValueFromJsonK(self.modelConfig,\"maxEnemyMissileNum\")\n",
    "        self.use_observation_mask=getValueFromJsonK(self.modelConfig,\"use_observation_mask\")\n",
    "        self.use_action_mask=getValueFromJsonK(self.modelConfig,\"use_action_mask\")\n",
    "        self.remaining_time_clipping=getValueFromJsonKR(self.modelConfig,\"remaining_time_clipping\",self.randomGen)\n",
    "        self.friend_dim=7\n",
    "        self.horizontalNormalizer=getValueFromJsonKR(self.modelConfig,\"horizontalNormalizer\",self.randomGen)\n",
    "        self.verticalNormalizer=getValueFromJsonKR(self.modelConfig,\"verticalNormalizer\",self.randomGen)\n",
    "        self.fgtrVelNormalizer=getValueFromJsonKR(self.modelConfig,\"fgtrVelNormalizer\",self.randomGen)\n",
    "        self.enemy_dim=7\n",
    "        self.friend_missile_dim=7\n",
    "        self.mslVelNormalizer=getValueFromJsonKR(self.modelConfig,\"mslVelNormalizer\",self.randomGen)\n",
    "        self.enemy_missile_dim = 3\n",
    "\n",
    "\n",
    "        #actionに関するもの\n",
    "        # 左右旋回に関する設定\n",
    "        self.dstAz_relative=getValueFromJsonK(self.modelConfig,\"dstAz_relative\")\n",
    "        self.turnTable=np.array(sorted(getValueFromJsonK(self.modelConfig,\"turnTable\")),dtype=np.float64)\n",
    "        self.turnTable*=deg2rad(1.0)\n",
    "        self.use_override_evasion=getValueFromJsonK(self.modelConfig,\"use_override_evasion\")\n",
    "        if self.use_override_evasion:\n",
    "            self.evasion_turnTable=np.array(sorted(getValueFromJsonK(self.modelConfig,\"evasion_turnTable\")),dtype=np.float64)\n",
    "            self.evasion_turnTable*=deg2rad(1.0)\n",
    "            assert len(self.turnTable)==len(self.evasion_turnTable)\n",
    "        else:\n",
    "            self.evasion_turnTable=self.turnTable\n",
    "\n",
    "        self.actionInfos={}\n",
    "        for port,parent in self.parents.items():\n",
    "            self.actionInfos[parent.getFullName()]=self.ActionInfo()\n",
    "\n",
    "        # 加減速に関する設定\n",
    "        self.accelTable=np.array(sorted(getValueFromJsonK(self.modelConfig,\"accelTable\")),dtype=np.float64)\n",
    "\n",
    "        #行動制限に関する設定\n",
    "        # 場外制限に関する設定\n",
    "        self.dOutLimit=getValueFromJsonKRD(self.modelConfig,\"dOutLimit\",self.randomGen,5000.0)\n",
    "        self.dOutLimitThreshold=getValueFromJsonKRD(self.modelConfig,\"dOutLimitThreshold\",self.randomGen,10000.0)\n",
    "        self.dOutLimitStrength=getValueFromJsonKRD(self.modelConfig,\"dOutLimitStrength\",self.randomGen,2e-3)\n",
    "\n",
    "        #  高度制限に関する設定\n",
    "        self.altMin=getValueFromJsonKRD(self.modelConfig,\"altMin\",self.randomGen,2000.0)\n",
    "        self.altMax=getValueFromJsonKRD(self.modelConfig,\"altMax\",self.randomGen,15000.0)\n",
    "        self.altitudeKeeper=AltitudeKeeper(self.modelConfig().get(\"altitudeKeeper\",{}))\n",
    "\n",
    "        # 同時射撃数の制限に関する設定\n",
    "        self.maxSimulShot=getValueFromJsonKRD(self.modelConfig,\"maxSimulShot\",self.randomGen,4)\n",
    "\n",
    "        # 下限速度の制限に関する設定\n",
    "        self.minimumV=getValueFromJsonKRD(self.modelConfig,\"minimumV\",self.randomGen,150.0)\n",
    "        self.minimumRecoveryV=getValueFromJsonKRD(self.modelConfig,\"minimumRecoveryV\",self.randomGen,180.0)\n",
    "        self.minimumRecoveryDstV=getValueFromJsonKRD(self.modelConfig,\"minimumRecoveryDstV\",self.randomGen,200.0)\n",
    "\n",
    "\n",
    "    def validate(self):\n",
    "        #Rulerに関する情報の取得\n",
    "        rulerObs=self.manager.getRuler()().observables()\n",
    "        self.dOut=rulerObs[\"dOut\"] # 戦域中心から場外ラインまでの距離\n",
    "        self.dLine=rulerObs[\"dLine\"] # 戦域中心から防衛ラインまでの距離\n",
    "        self.teamOrigin=TeamOrigin(self.own==rulerObs[\"eastSider\"],self.dLine) # 陣営座標系変換クラス定義\n",
    "\n",
    "\n",
    "    def makeObs(self):\n",
    "        obs = {}\n",
    "        observation_mask={}\n",
    "        \n",
    "        # common(残り時間)\n",
    "        ret=np.zeros([self.common_dim],dtype=np.float32)\n",
    "        rulerObs=self.manager.getRuler()().observables\n",
    "        maxTime=rulerObs['maxTime']()\n",
    "        ret[0]=min((maxTime-self.manager.getElapsedTime())/60.0, self.remaining_time_clipping)\n",
    "\n",
    "        obs['common'] = ret\n",
    "\n",
    "        #味方機(parents→parents以外の順)\n",
    "        ret = np.zeros([self.maxParentNum, self.friend_dim],dtype=np.float32)\n",
    "        parent_mask=np.zeros([self.maxParentNum],dtype=np.float32)\n",
    "        self.ourMotion=[]\n",
    "        self.ourObservables=[]\n",
    "        firstAlive=None\n",
    "        for port,parent in self.parents.items():\n",
    "            if parent.isAlive():\n",
    "                firstAlive=parent\n",
    "                break\n",
    "\n",
    "        parentFullNames=set()\n",
    "        # まずはparents\n",
    "        for port, parent in self.parents.items():\n",
    "            parentFullNames.add(parent.getFullName())\n",
    "            if parent.isAlive():\n",
    "                self.ourMotion.append(MotionState(parent.observables[\"motion\"]).transformTo(self.getLocalCRS()))\n",
    "                #残存していればobservablesそのもの\n",
    "                self.ourObservables.append(parent.observables)\n",
    "            else:\n",
    "                self.ourMotion.append(MotionState())\n",
    "                #被撃墜or墜落済なら本体の更新は止まっているので残存している親が代理更新したものを取得(誘導弾情報のため)\n",
    "                self.ourObservables.append(\n",
    "                    firstAlive.observables.at_p(\"/shared/fighter\").at(parent.getFullName()))\n",
    "\n",
    "        # その後にparents以外\n",
    "        for fullName,fObs in firstAlive.observables.at_p(\"/shared/fighter\").items():\n",
    "            if not fullName in parentFullNames:\n",
    "                if fObs.at(\"isAlive\"):\n",
    "                    self.ourMotion.append(MotionState(fObs[\"motion\"]).transformTo(self.getLocalCRS()))\n",
    "                else:\n",
    "                    self.ourMotion.append(MotionState())\n",
    "\n",
    "                self.ourObservables.append(fObs)\n",
    "        fIdx = 0\n",
    "        for port,parent in self.parents.items():\n",
    "            if fIdx>=self.maxParentNum:\n",
    "                break\n",
    "            fObs=self.ourObservables[fIdx]\n",
    "            fMotion=self.ourMotion[fIdx]\n",
    "            if fObs.at(\"isAlive\"):\n",
    "                parent_mask[fIdx]=1\n",
    "                pos=self.teamOrigin.relPtoB(fMotion.pos()) #慣性座標系→陣営座標系に変換\n",
    "                vel=self.teamOrigin.relPtoB(fMotion.vel()) #慣性座標系→陣営座標系に変換\n",
    "                a=np.zeros([self.friend_dim],dtype=np.float32)\n",
    "                ofs = 0\n",
    "                a[ofs:ofs+3]=pos/np.array([self.horizontalNormalizer,self.horizontalNormalizer,self.verticalNormalizer])\n",
    "                ofs += 3\n",
    "                V=np.linalg.norm(vel)\n",
    "                a[ofs]=V/self.fgtrVelNormalizer\n",
    "                ofs+=1\n",
    "                a[ofs:ofs+3]=vel/max(V, 1e-5)\n",
    "                ret[fIdx, :] = a\n",
    "            fIdx+=1\n",
    "\n",
    "        obs['parent'] = ret\n",
    "        if self.use_observation_mask:\n",
    "            observation_mask['parent']=parent_mask\n",
    "\n",
    "        #彼機(味方の誰かが探知しているもののみ)\n",
    "        #観測されている航跡を、自陣営の機体に近いものから順にソートしてlastTrackInfoに格納する。\n",
    "        #lastTrackInfoは行動のdeployでも射撃対象の指定のために参照する。\n",
    "        firstAlive=None\n",
    "        for port,parent in self.parents.items():\n",
    "            if parent.isAlive():\n",
    "                firstAlive=parent\n",
    "                break\n",
    "\n",
    "        self.lastTrackInfo=[Track3D(t).transformTo(self.getLocalCRS()) for t in firstAlive.observables.at_p(\"/sensor/track\")]\n",
    "        sortTrack3DByDistance(self.lastTrackInfo,self.ourMotion,True)\n",
    "\n",
    "        ret=np.zeros([self.maxEnemyNum,self.enemy_dim],dtype=np.float32)\n",
    "        enemy_mask=np.zeros([self.maxEnemyNum],dtype=np.float32)\n",
    "        for tIdx,track in enumerate(self.lastTrackInfo):\n",
    "            if tIdx>=self.maxEnemyNum:\n",
    "                break\n",
    "            t=np.zeros([self.enemy_dim],dtype=np.float32)\n",
    "            ofs=0\n",
    "            pos=self.teamOrigin.relPtoB(track.pos()) #慣性座標系→陣営座標系に変換\n",
    "            t[ofs:ofs+3]=pos/np.array([self.horizontalNormalizer,self.horizontalNormalizer,self.verticalNormalizer])\n",
    "            ofs+=3\n",
    "            vel=self.teamOrigin.relPtoB(track.vel()) #慣性座標系→陣営座標系に変換\n",
    "            V=np.linalg.norm(vel)\n",
    "            t[ofs]=V/self.fgtrVelNormalizer\n",
    "            ofs+=1\n",
    "            t[ofs:ofs+3]=vel/max(V, 1e-5)\n",
    "            ofs+=3\n",
    "            ret[tIdx,:]=t\n",
    "            enemy_mask[tIdx]=1\n",
    "\n",
    "        obs['enemy']=ret\n",
    "        if self.use_observation_mask:\n",
    "            observation_mask['enemy']=enemy_mask\n",
    "\n",
    "\n",
    "        #味方誘導弾(射撃時刻の古い順にソート\n",
    "        def launchedT(m):\n",
    "            return Time(m[\"launchedT\"]) if m[\"isAlive\"] and m[\"hasLaunched\"] else Time(np.inf,TimeSystem.TT)\n",
    "        self.msls=sorted(sum([[m for m in f.at_p(\"/weapon/missiles\")] for f in self.ourObservables],[]),key=launchedT)\n",
    "        ret=np.zeros([self.maxFriendMissileNum,self.friend_missile_dim],dtype=np.float32)\n",
    "        friend_missile_mask=np.zeros([self.maxFriendMissileNum],dtype=np.float32)\n",
    "        for mIdx,mObs in enumerate(self.msls):\n",
    "            if mIdx>=self.maxFriendMissileNum or not (mObs.at(\"isAlive\") and mObs.at(\"hasLaunched\")):\n",
    "                break\n",
    "            a=np.zeros([self.friend_missile_dim],dtype=np.float32)\n",
    "            ofs=0\n",
    "            mm=MotionState(mObs[\"motion\"]).transformTo(self.getLocalCRS())\n",
    "            pos=self.teamOrigin.relPtoB(mm.pos()) #慣性座標系→陣営座標系に変換\n",
    "            a[ofs:ofs+3]=pos/np.array([self.horizontalNormalizer,self.horizontalNormalizer,self.verticalNormalizer])\n",
    "            ofs+=3\n",
    "            vel=self.teamOrigin.relPtoB(mm.vel()) #慣性座標系→陣営座標系に変換\n",
    "            V=np.linalg.norm(vel)\n",
    "            a[ofs]=V/self.mslVelNormalizer\n",
    "            ofs+=1\n",
    "            a[ofs:ofs+3]=vel/max(V, 1e-5)\n",
    "            ret[mIdx,:]=a\n",
    "            friend_missile_mask[mIdx]=1\n",
    "        \n",
    "        obs['friend_missile'] = ret\n",
    "        if self.use_observation_mask:\n",
    "            observation_mask['friend_missile'] = friend_missile_mask\n",
    "\n",
    "        #彼側誘導弾(各機の正面に近い順にソート)\n",
    "        self.mws=[]\n",
    "        for fIdx,fMotion in enumerate(self.ourMotion):\n",
    "            fObs=self.ourObservables[fIdx]\n",
    "            self.mws.append([])\n",
    "            if fObs[\"isAlive\"]:\n",
    "                if fObs.contains_p(\"/sensor/mws/track\"):\n",
    "                    for mObs in fObs.at_p(\"/sensor/mws/track\"):\n",
    "                        self.mws[fIdx].append(Track2D(mObs).transformTo(self.getLocalCRS()))\n",
    "                sortTrack2DByAngle(self.mws[fIdx],fMotion,np.array([1,0,0]),True)\n",
    "        ret=np.zeros([self.maxEnemyMissileNum,self.enemy_missile_dim],dtype=np.float32)\n",
    "        enemy_missile_mask=np.zeros([self.maxEnemyMissileNum],dtype=np.float32)\n",
    "        allMWS=[]\n",
    "        for fIdx,fMotion in enumerate(self.ourMotion):\n",
    "            if self.ourObservables[fIdx].at(\"isAlive\"):\n",
    "                for m in self.mws[fIdx]:\n",
    "                    angle=np.arccos(np.clip(m.dir().dot(fMotion.dirBtoP(np.array([1,0,0]))),-1,1))\n",
    "                    allMWS.append([m,angle])\n",
    "        allMWS.sort(key=lambda x: x[1])\n",
    "        for mIdx,m in enumerate(allMWS):\n",
    "            if mIdx>=self.maxEnemyMissileNum:\n",
    "                break\n",
    "            a=np.zeros([self.enemy_missile_dim],dtype=np.float32)\n",
    "            ofs=0\n",
    "            origin=self.teamOrigin.relPtoB(m[0].origin()) #慣性座標系→陣営座標系に変換\n",
    "            a[ofs:ofs+3]=origin/np.array([self.horizontalNormalizer,self.horizontalNormalizer,self.verticalNormalizer])\n",
    "            ret[mIdx,:]=a\n",
    "            enemy_missile_mask[mIdx]=1\n",
    "        \n",
    "        obs['enemy_missile'] = ret\n",
    "        if self.use_observation_mask:\n",
    "            observation_mask['enemy_missile']=enemy_missile_mask\n",
    "\n",
    "        if self.use_observation_mask and len(observation_mask)>0:\n",
    "            obs['observation_mask']=observation_mask\n",
    "\n",
    "        if self.use_action_mask:\n",
    "            self.action_mask=self.makeActionMask()\n",
    "            if not self.action_mask is None:\n",
    "                obs['action_mask']=self.action_mask\n",
    "\n",
    "\n",
    "        return obs\n",
    "\n",
    "\n",
    "    def makeActionMask(self):\n",
    "        #無効な行動を示すマスクを返す\n",
    "        #有効な場合は1、無効な場合は0とする。\n",
    "        if self.use_action_mask:\n",
    "            #このサンプルでは射撃目標のみマスクする。\n",
    "            target_mask=np.zeros([1+self.maxEnemyNum],dtype=np.float32)\n",
    "            target_mask[0]=1#「射撃なし」はつねに有効\n",
    "            for tIdx,track in enumerate(self.lastTrackInfo):\n",
    "                if tIdx>=self.maxEnemyNum:\n",
    "                    break\n",
    "                target_mask[1+tIdx]=1\n",
    "\n",
    "            ret=[]\n",
    "            for port,parent in self.parents.items():\n",
    "                mask={}\n",
    "                mask[\"turn\"]=np.full([len(self.turnTable)],1,dtype=np.float32)\n",
    "                mask[\"accel\"]=np.full([len(self.accelTable)],1,dtype=np.float32)\n",
    "                mask[\"target\"]=target_mask\n",
    "                ret.append(mask)\n",
    "            return ret\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "    def observation_space(self):\n",
    "        floatLow=np.finfo(np.float32).min\n",
    "        floatHigh=np.finfo(np.float32).max\n",
    "        obs_space = {\n",
    "            'common': spaces.Box(floatLow,floatHigh,\n",
    "                                 shape=[self.common_dim],\n",
    "                                 dtype=np.float32),\n",
    "            'parent': spaces.Box(floatLow,floatHigh,\n",
    "                                 shape=[self.maxParentNum,self.friend_dim],\n",
    "                                 dtype=np.float32),\n",
    "            'enemy': spaces.Box(floatLow,floatHigh,\n",
    "                                shape=[self.maxEnemyNum,self.enemy_dim],\n",
    "                                dtype=np.float32),\n",
    "            'friend_missile': spaces.Box(floatLow,floatHigh,\n",
    "                                         shape=[self.maxFriendMissileNum,self.friend_missile_dim],\n",
    "                                         dtype=np.float32),\n",
    "            'enemy_missile': spaces.Box(floatLow,floatHigh,\n",
    "                                        shape=[self.maxEnemyMissileNum,self.enemy_missile_dim],\n",
    "                                        dtype=np.float32)\n",
    "        }\n",
    "        if self.use_observation_mask:\n",
    "            observation_mask = {\n",
    "                'parent': spaces.Box(floatLow,floatHigh,\n",
    "                                     shape=[self.maxParentNum],\n",
    "                                     dtype=np.float32),\n",
    "                'enemy': spaces.Box(floatLow,floatHigh,\n",
    "                                    shape=[self.maxEnemyNum],\n",
    "                                    dtype=np.float32),\n",
    "                'friend_missile': spaces.Box(floatLow,floatHigh,\n",
    "                                             shape=[self.maxFriendMissileNum],\n",
    "                                             dtype=np.float32),\n",
    "                'enemy_missile': spaces.Box(floatLow,floatHigh,\n",
    "                                            shape=[self.maxEnemyMissileNum],\n",
    "                                            dtype=np.float32)\n",
    "            }\n",
    "            obs_space['observation_mask'] = spaces.Dict(observation_mask) # type: ignore\n",
    "\n",
    "        if self.use_action_mask:\n",
    "            single_action_mask_space_dict = {\n",
    "                'turn': spaces.Box(floatLow,floatHigh,\n",
    "                                   shape=[len(self.turnTable)],\n",
    "                                   dtype=np.float32),\n",
    "                'accel': spaces.Box(floatLow,floatHigh,\n",
    "                                    shape=[len(self.accelTable)],\n",
    "                                    dtype=np.float32),\n",
    "                'target': spaces.Box(floatLow,floatHigh,\n",
    "                                     shape=[1+self.maxEnemyNum],\n",
    "                                     dtype=np.float32)\n",
    "            }\n",
    "            single_action_mask_space=spaces.Dict(single_action_mask_space_dict) # type: ignore\n",
    "            action_mask_space_list=[]\n",
    "            for port, parent in self.parents.items():\n",
    "                action_mask_space_list.append(single_action_mask_space)\n",
    "            obs_space['action_mask'] = spaces.Tuple(action_mask_space_list) # type: ignore\n",
    "\n",
    "        return spaces.Dict(obs_space) # type: ignore\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### `action_space`メソッドの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "actionは`policy`によって返されて, `deploy`メソッドに渡されて自機の動きや誘導弾発射の意思決定などを行う. 今回のシミュレーション時刻の最小単位(tick)は1.0sである. 行動判断モデルが gymnasium インターフェースの外側で行動判断を行う周期はこれより長くしてもよい.\n",
    "\n",
    "以下の項目に関連するような行動を定義しておく.\n",
    "\n",
    "1. 自分と味方の機動\n",
    "    - ある基準方位を0として目標方位(右を正)で指定する。\n",
    "    - 基準方位は、dstAz_relativeフラグをTrueとした場合、自機正面となり、Falseとした場合、自陣営の進行すべき方向となる。\n",
    "    - 目標方位の選択肢はturnTableで与える。\n",
    "1. 射撃有無と射撃対象\n",
    "    - 0を射撃なし、1〜maxEnemyNumを対応するlastTrackInfoのTrack3DとしたDiscrete形式で指定する\n",
    "\n",
    "actionが存在すべき行動空間(このあと実装するpolicyの出力するactionの種類数)を定義する. 各parentのactionを表すDictをparentの数だけ並べたTupleとする. なお, 強化学習を前提としない場合は特に気にすることはなく何らかの適当な値を返すような実装としておいてもよい(`spaces.Discrete()`を返すなど).\n",
    "\n",
    "[「第4回空戦AIチャレンジ向け強化学習 Agent サンプル/実装の概要/actionの形式」](http://localhost:5500/docs/html/core/a198025.html#section_r7_contest_agent_sample_action)も参照されたい.\n",
    "\n",
    "`deploy`メソッドの実装例も示してあるので, policyが返した`action`をどのように渡しているか確認. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium import spaces\n",
    "from math import atan2, cos, sin\n",
    "from BasicAgentUtility.util import calcRNorm\n",
    "\n",
    "\n",
    "class SampleAgent(Agent):\n",
    "    ...\n",
    "    def action_space(self):\n",
    "        single_action_space_dict={\n",
    "            'turn': spaces.Discrete(len(self.turnTable)),\n",
    "            'target': spaces.Discrete(1+self.maxEnemyNum),\n",
    "            'accel': spaces.Discrete(len(self.accelTable))\n",
    "        }\n",
    "        single_action_space=spaces.Dict(single_action_space_dict) # type: ignore\n",
    "        action_space_list=[]\n",
    "        for port, parent in self.parents.items():\n",
    "            action_space_list.append(single_action_space)\n",
    "        return spaces.Tuple(action_space_list) # 行動空間の定義\n",
    "    \n",
    "\n",
    "    def deploy(self, action):\n",
    "        #observablesの収集\n",
    "        #味方機(parents→parents以外の順)\n",
    "        self.ourMotion=[]\n",
    "        self.ourObservables=[]\n",
    "        firstAlive=None\n",
    "        for port,parent in self.parents.items():\n",
    "            if parent.isAlive():\n",
    "                firstAlive=parent\n",
    "                break\n",
    "\n",
    "        parentFullNames=set()\n",
    "        # まずはparents\n",
    "        for port, parent in self.parents.items():\n",
    "            parentFullNames.add(parent.getFullName())\n",
    "            if parent.isAlive():\n",
    "                self.ourMotion.append(MotionState(parent.observables[\"motion\"]).transformTo(self.getLocalCRS()))\n",
    "                #残存していればobservablesそのもの\n",
    "                self.ourObservables.append(parent.observables)\n",
    "            else:\n",
    "                self.ourMotion.append(MotionState())\n",
    "                #被撃墜or墜落済なら本体の更新は止まっているので残存している親が代理更新したものを取得(誘導弾情報のため)\n",
    "                self.ourObservables.append(\n",
    "                    firstAlive.observables.at_p(\"/shared/fighter\").at(parent.getFullName()))\n",
    "\n",
    "        # その後にparents以外\n",
    "        for fullName,fObs in firstAlive.observables.at_p(\"/shared/fighter\").items():\n",
    "            if not fullName in parentFullNames:\n",
    "                if fObs.at(\"isAlive\"):\n",
    "                    self.ourMotion.append(MotionState(fObs[\"motion\"]).transformTo(self.getLocalCRS()))\n",
    "                else:\n",
    "                    self.ourMotion.append(MotionState())\n",
    "\n",
    "                self.ourObservables.append(fObs)\n",
    "\n",
    "\n",
    "        # 彼機情報だけは射撃対象の選択と連動するので更新してはいけない。\n",
    "        #味方誘導弾(射撃時刻の古い順にソート)\n",
    "        def launchedT(m):\n",
    "            return Time(m[\"launchedT\"]) if m[\"isAlive\"] and m[\"hasLaunched\"] else Time(np.inf,TimeSystem.TT)\n",
    "        self.msls=sorted(sum([[m for m in f.at_p(\"/weapon/missiles\")] for f in self.ourObservables],[]),key=launchedT)\n",
    "\n",
    "        #彼側誘導弾(各機の正面に近い順にソート)\n",
    "        self.mws=[]\n",
    "        for fIdx,fMotion in enumerate(self.ourMotion):\n",
    "            fObs=self.ourObservables[fIdx]\n",
    "            self.mws.append([])\n",
    "            if fObs[\"isAlive\"]:\n",
    "                if fObs.contains_p(\"/sensor/mws/track\"):\n",
    "                    for mObs in fObs.at_p(\"/sensor/mws/track\"):\n",
    "                        self.mws[fIdx].append(Track2D(mObs).transformTo(self.getLocalCRS()))\n",
    "                sortTrack2DByAngle(self.mws[fIdx],fMotion,np.array([1,0,0]),True)\n",
    "\n",
    "        for pIdx,parent in enumerate(self.parents.values()):\n",
    "            parentFullName=parent.getFullName()\n",
    "            if not parent.isAlive():\n",
    "                continue\n",
    "            actionInfo=self.actionInfos[parentFullName]\n",
    "            myMotion=self.ourMotion[pIdx]\n",
    "            myObs=self.ourObservables[pIdx]\n",
    "            myMWS=self.mws[pIdx]\n",
    "            myAction=action[pIdx]\n",
    "\n",
    "            #左右旋回\n",
    "            deltaAz=self.turnTable[myAction[\"turn\"]]\n",
    "            actionInfo.dstDir=self.teamOrigin.relBtoP(np.array([cos(deltaAz),sin(deltaAz),0]))\n",
    "            dstAz=atan2(actionInfo.dstDir[1],actionInfo.dstDir[0])\n",
    "\n",
    "            #上昇・下降\n",
    "            dstPitch=0\n",
    "            actionInfo.dstDir=np.array([actionInfo.dstDir[0]*cos(dstPitch),actionInfo.dstDir[1]*cos(dstPitch),-sin(dstPitch)])\n",
    "\n",
    "            #加減速\n",
    "            V=np.linalg.norm(myMotion.vel())\n",
    "            actionInfo.asThrottle=False\n",
    "            accel=self.accelTable[myAction[\"accel\"]]\n",
    "            actionInfo.dstV=V+accel\n",
    "            actionInfo.keepVel = accel==0.0\n",
    "\n",
    "            #下限速度の制限\n",
    "            if V<self.minimumV:\n",
    "                actionInfo.velRecovery=True\n",
    "            if V>=self.minimumRecoveryV:\n",
    "                actionInfo.velRecovery=False\n",
    "            if actionInfo.velRecovery:\n",
    "                actionInfo.dstV=self.minimumRecoveryDstV\n",
    "                actionInfo.asThrottle=False\n",
    "\n",
    "            #射撃\n",
    "            #actionのパース\n",
    "            shotTarget=myAction[\"target\"]-1\n",
    "\n",
    "            #射撃可否の判断、射撃コマンドの生成\n",
    "            flyingMsls=0\n",
    "            if myObs.contains_p(\"/weapon/missiles\"):\n",
    "                for msl in myObs.at_p(\"/weapon/missiles\"):\n",
    "                    if msl.at(\"isAlive\")() and msl.at(\"hasLaunched\")():\n",
    "                        flyingMsls+=1\n",
    "            if not (\n",
    "                shotTarget>=0 and\n",
    "                shotTarget<len(self.lastTrackInfo) and\n",
    "                parent.isLaunchableAt(self.lastTrackInfo[shotTarget]) and\n",
    "                flyingMsls<self.maxSimulShot\n",
    "            ):\n",
    "                shotTarget=-1\n",
    "            if shotTarget>=0:\n",
    "                actionInfo.launchFlag=True\n",
    "                actionInfo.target=self.lastTrackInfo[shotTarget]\n",
    "            else:\n",
    "                actionInfo.launchFlag=False\n",
    "                actionInfo.target=Track3D()\n",
    "\n",
    "            self.observables[parentFullName][\"decision\"]={\n",
    "                \"Roll\":(\"Don't care\"),\n",
    "                \"Fire\":(actionInfo.launchFlag,actionInfo.target.to_json())\n",
    "            }\n",
    "            if len(myMWS)>0 and self.use_override_evasion:\n",
    "                self.observables[parentFullName][\"decision\"][\"Horizontal\"]=(\"Az_NED\",dstAz)\n",
    "            else:\n",
    "                if self.dstAz_relative:\n",
    "                    self.observables[parentFullName][\"decision\"][\"Horizontal\"]=(\"Az_BODY\",deltaAz)\n",
    "                else:\n",
    "                    self.observables[parentFullName][\"decision\"][\"Horizontal\"]=(\"Az_NED\",dstAz)\n",
    "            self.observables[parentFullName][\"decision\"][\"Vertical\"]=(\"El\",dstPitch)\n",
    "            if actionInfo.asThrottle:\n",
    "                self.observables[parentFullName][\"decision\"][\"Throttle\"]=(\"Throttle\",actionInfo.dstThrottle)\n",
    "            else:\n",
    "                self.observables[parentFullName][\"decision\"][\"Throttle\"]=(\"Vel\",actionInfo.dstV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 全てをまとめる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下では定義したactionなどに合わせて`deploy`や`control`メソッドなどを含めたすべてを示してある. `control`メソッドでは場外に出ないような制御をかけている. これを`MyAgent.py`として作成しておく(中央集権方式)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ASRCAISim1.core import Agent, getValueFromJsonK, getValueFromJsonKR, getValueFromJsonKRD, LinearSegment, MotionState, Track3D, Track2D, Time, TimeSystem, deg2rad, serialize_attr_with_type_info, StaticCollisionAvoider2D,AltitudeKeeper# type: ignore\n",
    "from BasicAgentUtility.util import TeamOrigin, sortTrack3DByDistance, sortTrack2DByAngle, calcRNorm # type: ignore\n",
    "from math import atan2, cos, sin, sqrt\n",
    "from gymnasium import spaces\n",
    "\n",
    "\n",
    "class SampleAgent(Agent):\n",
    "    class ActionInfo:\n",
    "        #機体に対するコマンドを生成するための変数をまとめた構造体\n",
    "        def __init__(self):\n",
    "            self.dstDir=np.array([1.0,0.0,0.0]) #目標進行方向\n",
    "            self.dstAlt=10000.0 #目標高度\n",
    "            self.velRecovery=False #下限速度制限からの回復中かどうか\n",
    "            self.asThrottle=False #加減速についてスロットルでコマンドを生成するかどうか\n",
    "            self.keepVel=False #加減速について等速(dstAccel=0)としてコマンドを生成するかどうか\n",
    "            self.dstThrottle=1.0 #目標スロットル\n",
    "            self.dstV=300 #目標速度\n",
    "            self.launchFlag=False #射撃するかどうか\n",
    "            self.target=Track3D() #射撃対象\n",
    "            self.lastShotTimes={} #各Trackに対する直前の射撃時刻\n",
    "        def serialize(self, archive):\n",
    "            serialize_attr_with_type_info(archive, self\n",
    "                ,\"dstDir\"\n",
    "                ,\"dstAlt\"\n",
    "                ,\"velRecovery\"\n",
    "                ,\"asThrottle\"\n",
    "                ,\"keepVel\"\n",
    "                ,\"dstThrottle\"\n",
    "                ,\"dstV\"\n",
    "                ,\"launchFlag\"\n",
    "                ,\"target\"\n",
    "                ,\"lastShotTimes\"\n",
    "            )\n",
    "        _allow_cereal_serialization_in_cpp = True\n",
    "        def save(self, archive):\n",
    "            self.serialize(archive)\n",
    "        @classmethod\n",
    "        def static_load(cls, archive):\n",
    "            ret=cls()\n",
    "            ret.serialize(archive)\n",
    "            return ret\n",
    "\n",
    "\n",
    "    def initialize(self):\n",
    "        super().initialize()\n",
    "        self.own = self.getTeam()\n",
    "        self.common_dim = 1\n",
    "        self.maxParentNum=getValueFromJsonK(self.modelConfig,\"maxParentNum\")\n",
    "        self.maxFriendNum=getValueFromJsonK(self.modelConfig,\"maxFriendNum\")\n",
    "        self.maxEnemyNum=getValueFromJsonK(self.modelConfig,\"maxEnemyNum\")\n",
    "        self.maxFriendMissileNum=getValueFromJsonK(self.modelConfig,\"maxFriendMissileNum\")\n",
    "        self.maxEnemyMissileNum=getValueFromJsonK(self.modelConfig,\"maxEnemyMissileNum\")\n",
    "        self.use_observation_mask=getValueFromJsonK(self.modelConfig,\"use_observation_mask\")\n",
    "        self.use_action_mask=getValueFromJsonK(self.modelConfig,\"use_action_mask\")\n",
    "        self.remaining_time_clipping=getValueFromJsonKR(self.modelConfig,\"remaining_time_clipping\",self.randomGen)\n",
    "        self.friend_dim=7\n",
    "        self.horizontalNormalizer=getValueFromJsonKR(self.modelConfig,\"horizontalNormalizer\",self.randomGen)\n",
    "        self.verticalNormalizer=getValueFromJsonKR(self.modelConfig,\"verticalNormalizer\",self.randomGen)\n",
    "        self.fgtrVelNormalizer=getValueFromJsonKR(self.modelConfig,\"fgtrVelNormalizer\",self.randomGen)\n",
    "        self.enemy_dim=7\n",
    "        self.friend_missile_dim=7\n",
    "        self.mslVelNormalizer=getValueFromJsonKR(self.modelConfig,\"mslVelNormalizer\",self.randomGen)\n",
    "        self.enemy_missile_dim = 3\n",
    "\n",
    "\n",
    "        #actionに関するもの\n",
    "        # 左右旋回に関する設定\n",
    "        self.dstAz_relative=getValueFromJsonK(self.modelConfig,\"dstAz_relative\")\n",
    "        self.turnTable=np.array(sorted(getValueFromJsonK(self.modelConfig,\"turnTable\")),dtype=np.float64)\n",
    "        self.turnTable*=deg2rad(1.0)\n",
    "        self.use_override_evasion=getValueFromJsonK(self.modelConfig,\"use_override_evasion\")\n",
    "        if self.use_override_evasion:\n",
    "            self.evasion_turnTable=np.array(sorted(getValueFromJsonK(self.modelConfig,\"evasion_turnTable\")),dtype=np.float64)\n",
    "            self.evasion_turnTable*=deg2rad(1.0)\n",
    "            assert len(self.turnTable)==len(self.evasion_turnTable)\n",
    "        else:\n",
    "            self.evasion_turnTable=self.turnTable\n",
    "\n",
    "        self.actionInfos={}\n",
    "        for port,parent in self.parents.items():\n",
    "            self.actionInfos[parent.getFullName()]=self.ActionInfo()\n",
    "\n",
    "        # 加減速に関する設定\n",
    "        self.accelTable=np.array(sorted(getValueFromJsonK(self.modelConfig,\"accelTable\")),dtype=np.float64)\n",
    "\n",
    "        #行動制限に関する設定\n",
    "        # 場外制限に関する設定\n",
    "        self.dOutLimit=getValueFromJsonKRD(self.modelConfig,\"dOutLimit\",self.randomGen,5000.0)\n",
    "        self.dOutLimitThreshold=getValueFromJsonKRD(self.modelConfig,\"dOutLimitThreshold\",self.randomGen,10000.0)\n",
    "        self.dOutLimitStrength=getValueFromJsonKRD(self.modelConfig,\"dOutLimitStrength\",self.randomGen,2e-3)\n",
    "\n",
    "        #  高度制限に関する設定\n",
    "        self.altMin=getValueFromJsonKRD(self.modelConfig,\"altMin\",self.randomGen,2000.0)\n",
    "        self.altMax=getValueFromJsonKRD(self.modelConfig,\"altMax\",self.randomGen,15000.0)\n",
    "        self.altitudeKeeper=AltitudeKeeper(self.modelConfig().get(\"altitudeKeeper\",{}))\n",
    "\n",
    "        # 同時射撃数の制限に関する設定\n",
    "        self.maxSimulShot=getValueFromJsonKRD(self.modelConfig,\"maxSimulShot\",self.randomGen,4)\n",
    "\n",
    "        # 下限速度の制限に関する設定\n",
    "        self.minimumV=getValueFromJsonKRD(self.modelConfig,\"minimumV\",self.randomGen,150.0)\n",
    "        self.minimumRecoveryV=getValueFromJsonKRD(self.modelConfig,\"minimumRecoveryV\",self.randomGen,180.0)\n",
    "        self.minimumRecoveryDstV=getValueFromJsonKRD(self.modelConfig,\"minimumRecoveryDstV\",self.randomGen,200.0)\n",
    "\n",
    "\n",
    "    def validate(self):\n",
    "        #Rulerに関する情報の取得\n",
    "        rulerObs=self.manager.getRuler()().observables()\n",
    "        self.dOut=rulerObs[\"dOut\"] # 戦域中心から場外ラインまでの距離\n",
    "        self.dLine=rulerObs[\"dLine\"] # 戦域中心から防衛ラインまでの距離\n",
    "        self.teamOrigin=TeamOrigin(self.own==rulerObs[\"eastSider\"],self.dLine) # 陣営座標系変換クラス定義\n",
    "\n",
    "\n",
    "    def makeObs(self):\n",
    "        obs = {}\n",
    "        observation_mask={}\n",
    "        \n",
    "        # common(残り時間)\n",
    "        ret=np.zeros([self.common_dim],dtype=np.float32)\n",
    "        rulerObs=self.manager.getRuler()().observables\n",
    "        maxTime=rulerObs['maxTime']()\n",
    "        ret[0]=min((maxTime-self.manager.getElapsedTime())/60.0, self.remaining_time_clipping)\n",
    "\n",
    "        obs['common'] = ret\n",
    "\n",
    "        #味方機(parents→parents以外の順)\n",
    "        ret = np.zeros([self.maxParentNum, self.friend_dim],dtype=np.float32)\n",
    "        parent_mask=np.zeros([self.maxParentNum],dtype=np.float32)\n",
    "        self.ourMotion=[]\n",
    "        self.ourObservables=[]\n",
    "        firstAlive=None\n",
    "        for port,parent in self.parents.items():\n",
    "            if parent.isAlive():\n",
    "                firstAlive=parent\n",
    "                break\n",
    "\n",
    "        parentFullNames=set()\n",
    "        # まずはparents\n",
    "        for port, parent in self.parents.items():\n",
    "            parentFullNames.add(parent.getFullName())\n",
    "            if parent.isAlive():\n",
    "                self.ourMotion.append(MotionState(parent.observables[\"motion\"]).transformTo(self.getLocalCRS()))\n",
    "                #残存していればobservablesそのもの\n",
    "                self.ourObservables.append(parent.observables)\n",
    "            else:\n",
    "                self.ourMotion.append(MotionState())\n",
    "                #被撃墜or墜落済なら本体の更新は止まっているので残存している親が代理更新したものを取得(誘導弾情報のため)\n",
    "                self.ourObservables.append(\n",
    "                    firstAlive.observables.at_p(\"/shared/fighter\").at(parent.getFullName()))\n",
    "\n",
    "        # その後にparents以外\n",
    "        for fullName,fObs in firstAlive.observables.at_p(\"/shared/fighter\").items():\n",
    "            if not fullName in parentFullNames:\n",
    "                if fObs.at(\"isAlive\"):\n",
    "                    self.ourMotion.append(MotionState(fObs[\"motion\"]).transformTo(self.getLocalCRS()))\n",
    "                else:\n",
    "                    self.ourMotion.append(MotionState())\n",
    "\n",
    "                self.ourObservables.append(fObs)\n",
    "        fIdx = 0\n",
    "        for port,parent in self.parents.items():\n",
    "            if fIdx>=self.maxParentNum:\n",
    "                break\n",
    "            fObs=self.ourObservables[fIdx]\n",
    "            fMotion=self.ourMotion[fIdx]\n",
    "            if fObs.at(\"isAlive\"):\n",
    "                parent_mask[fIdx]=1\n",
    "                pos=self.teamOrigin.relPtoB(fMotion.pos()) #慣性座標系→陣営座標系に変換\n",
    "                vel=self.teamOrigin.relPtoB(fMotion.vel()) #慣性座標系→陣営座標系に変換\n",
    "                a=np.zeros([self.friend_dim],dtype=np.float32)\n",
    "                ofs = 0\n",
    "                a[ofs:ofs+3]=pos/np.array([self.horizontalNormalizer,self.horizontalNormalizer,self.verticalNormalizer])\n",
    "                ofs += 3\n",
    "                V=np.linalg.norm(vel)\n",
    "                a[ofs]=V/self.fgtrVelNormalizer\n",
    "                ofs+=1\n",
    "                a[ofs:ofs+3]=vel/max(V, 1e-5)\n",
    "                ret[fIdx, :] = a\n",
    "            fIdx+=1\n",
    "\n",
    "        obs['parent'] = ret\n",
    "        if self.use_observation_mask:\n",
    "            observation_mask['parent']=parent_mask\n",
    "\n",
    "        #彼機(味方の誰かが探知しているもののみ)\n",
    "        #観測されている航跡を、自陣営の機体に近いものから順にソートしてlastTrackInfoに格納する。\n",
    "        #lastTrackInfoは行動のdeployでも射撃対象の指定のために参照する。\n",
    "        firstAlive=None\n",
    "        for port,parent in self.parents.items():\n",
    "            if parent.isAlive():\n",
    "                firstAlive=parent\n",
    "                break\n",
    "\n",
    "        self.lastTrackInfo=[Track3D(t).transformTo(self.getLocalCRS()) for t in firstAlive.observables.at_p(\"/sensor/track\")]\n",
    "        sortTrack3DByDistance(self.lastTrackInfo,self.ourMotion,True)\n",
    "\n",
    "        ret=np.zeros([self.maxEnemyNum,self.enemy_dim],dtype=np.float32)\n",
    "        enemy_mask=np.zeros([self.maxEnemyNum],dtype=np.float32)\n",
    "        for tIdx,track in enumerate(self.lastTrackInfo):\n",
    "            if tIdx>=self.maxEnemyNum:\n",
    "                break\n",
    "            t=np.zeros([self.enemy_dim],dtype=np.float32)\n",
    "            ofs=0\n",
    "            pos=self.teamOrigin.relPtoB(track.pos()) #慣性座標系→陣営座標系に変換\n",
    "            t[ofs:ofs+3]=pos/np.array([self.horizontalNormalizer,self.horizontalNormalizer,self.verticalNormalizer])\n",
    "            ofs+=3\n",
    "            vel=self.teamOrigin.relPtoB(track.vel()) #慣性座標系→陣営座標系に変換\n",
    "            V=np.linalg.norm(vel)\n",
    "            t[ofs]=V/self.fgtrVelNormalizer\n",
    "            ofs+=1\n",
    "            t[ofs:ofs+3]=vel/max(V, 1e-5)\n",
    "            ofs+=3\n",
    "            ret[tIdx,:]=t\n",
    "            enemy_mask[tIdx]=1\n",
    "\n",
    "        obs['enemy']=ret\n",
    "        if self.use_observation_mask:\n",
    "            observation_mask['enemy']=enemy_mask\n",
    "\n",
    "\n",
    "        #味方誘導弾(射撃時刻の古い順にソート\n",
    "        def launchedT(m):\n",
    "            return Time(m[\"launchedT\"]) if m[\"isAlive\"] and m[\"hasLaunched\"] else Time(np.inf,TimeSystem.TT)\n",
    "        self.msls=sorted(sum([[m for m in f.at_p(\"/weapon/missiles\")] for f in self.ourObservables],[]),key=launchedT)\n",
    "        ret=np.zeros([self.maxFriendMissileNum,self.friend_missile_dim],dtype=np.float32)\n",
    "        friend_missile_mask=np.zeros([self.maxFriendMissileNum],dtype=np.float32)\n",
    "        for mIdx,mObs in enumerate(self.msls):\n",
    "            if mIdx>=self.maxFriendMissileNum or not (mObs.at(\"isAlive\") and mObs.at(\"hasLaunched\")):\n",
    "                break\n",
    "            a=np.zeros([self.friend_missile_dim],dtype=np.float32)\n",
    "            ofs=0\n",
    "            mm=MotionState(mObs[\"motion\"]).transformTo(self.getLocalCRS())\n",
    "            pos=self.teamOrigin.relPtoB(mm.pos()) #慣性座標系→陣営座標系に変換\n",
    "            a[ofs:ofs+3]=pos/np.array([self.horizontalNormalizer,self.horizontalNormalizer,self.verticalNormalizer])\n",
    "            ofs+=3\n",
    "            vel=self.teamOrigin.relPtoB(mm.vel()) #慣性座標系→陣営座標系に変換\n",
    "            V=np.linalg.norm(vel)\n",
    "            a[ofs]=V/self.mslVelNormalizer\n",
    "            ofs+=1\n",
    "            a[ofs:ofs+3]=vel/max(V, 1e-5)\n",
    "            ret[mIdx,:]=a\n",
    "            friend_missile_mask[mIdx]=1\n",
    "        \n",
    "        obs['friend_missile'] = ret\n",
    "        if self.use_observation_mask:\n",
    "            observation_mask['friend_missile'] = friend_missile_mask\n",
    "\n",
    "        #彼側誘導弾(各機の正面に近い順にソート)\n",
    "        self.mws=[]\n",
    "        for fIdx,fMotion in enumerate(self.ourMotion):\n",
    "            fObs=self.ourObservables[fIdx]\n",
    "            self.mws.append([])\n",
    "            if fObs[\"isAlive\"]:\n",
    "                if fObs.contains_p(\"/sensor/mws/track\"):\n",
    "                    for mObs in fObs.at_p(\"/sensor/mws/track\"):\n",
    "                        self.mws[fIdx].append(Track2D(mObs).transformTo(self.getLocalCRS()))\n",
    "                sortTrack2DByAngle(self.mws[fIdx],fMotion,np.array([1,0,0]),True)\n",
    "        ret=np.zeros([self.maxEnemyMissileNum,self.enemy_missile_dim],dtype=np.float32)\n",
    "        enemy_missile_mask=np.zeros([self.maxEnemyMissileNum],dtype=np.float32)\n",
    "        allMWS=[]\n",
    "        for fIdx,fMotion in enumerate(self.ourMotion):\n",
    "            if self.ourObservables[fIdx].at(\"isAlive\"):\n",
    "                for m in self.mws[fIdx]:\n",
    "                    angle=np.arccos(np.clip(m.dir().dot(fMotion.dirBtoP(np.array([1,0,0]))),-1,1))\n",
    "                    allMWS.append([m,angle])\n",
    "        allMWS.sort(key=lambda x: x[1])\n",
    "        for mIdx,m in enumerate(allMWS):\n",
    "            if mIdx>=self.maxEnemyMissileNum:\n",
    "                break\n",
    "            a=np.zeros([self.enemy_missile_dim],dtype=np.float32)\n",
    "            ofs=0\n",
    "            origin=self.teamOrigin.relPtoB(m[0].origin()) #慣性座標系→陣営座標系に変換\n",
    "            a[ofs:ofs+3]=origin/np.array([self.horizontalNormalizer,self.horizontalNormalizer,self.verticalNormalizer])\n",
    "            ret[mIdx,:]=a\n",
    "            enemy_missile_mask[mIdx]=1\n",
    "        \n",
    "        obs['enemy_missile'] = ret\n",
    "        if self.use_observation_mask:\n",
    "            observation_mask['enemy_missile']=enemy_missile_mask\n",
    "\n",
    "        if self.use_observation_mask and len(observation_mask)>0:\n",
    "            obs['observation_mask']=observation_mask\n",
    "\n",
    "        if self.use_action_mask:\n",
    "            self.action_mask=self.makeActionMask()\n",
    "            if not self.action_mask is None:\n",
    "                obs['action_mask']=self.action_mask\n",
    "\n",
    "\n",
    "        return obs\n",
    "\n",
    "\n",
    "    def makeActionMask(self):\n",
    "        #無効な行動を示すマスクを返す\n",
    "        #有効な場合は1、無効な場合は0とする。\n",
    "        if self.use_action_mask:\n",
    "            #このサンプルでは射撃目標のみマスクする。\n",
    "            target_mask=np.zeros([1+self.maxEnemyNum],dtype=np.float32)\n",
    "            target_mask[0]=1#「射撃なし」はつねに有効\n",
    "            for tIdx,track in enumerate(self.lastTrackInfo):\n",
    "                if tIdx>=self.maxEnemyNum:\n",
    "                    break\n",
    "                target_mask[1+tIdx]=1\n",
    "\n",
    "            ret=[]\n",
    "            for port,parent in self.parents.items():\n",
    "                mask={}\n",
    "                mask[\"turn\"]=np.full([len(self.turnTable)],1,dtype=np.float32)\n",
    "                mask[\"accel\"]=np.full([len(self.accelTable)],1,dtype=np.float32)\n",
    "                mask[\"target\"]=target_mask\n",
    "                ret.append(mask)\n",
    "            return ret\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "    def observation_space(self):\n",
    "        floatLow=np.finfo(np.float32).min\n",
    "        floatHigh=np.finfo(np.float32).max\n",
    "        obs_space = {\n",
    "            'common': spaces.Box(floatLow,floatHigh,\n",
    "                                 shape=[self.common_dim],\n",
    "                                 dtype=np.float32),\n",
    "            'parent': spaces.Box(floatLow,floatHigh,\n",
    "                                 shape=[self.maxParentNum,self.friend_dim],\n",
    "                                 dtype=np.float32),\n",
    "            'enemy': spaces.Box(floatLow,floatHigh,\n",
    "                                shape=[self.maxEnemyNum,self.enemy_dim],\n",
    "                                dtype=np.float32),\n",
    "            'friend_missile': spaces.Box(floatLow,floatHigh,\n",
    "                                         shape=[self.maxFriendMissileNum,self.friend_missile_dim],\n",
    "                                         dtype=np.float32),\n",
    "            'enemy_missile': spaces.Box(floatLow,floatHigh,\n",
    "                                        shape=[self.maxEnemyMissileNum,self.enemy_missile_dim],\n",
    "                                        dtype=np.float32)\n",
    "        }\n",
    "        if self.use_observation_mask:\n",
    "            observation_mask = {\n",
    "                'parent': spaces.Box(floatLow,floatHigh,\n",
    "                                     shape=[self.maxParentNum],\n",
    "                                     dtype=np.float32),\n",
    "                'enemy': spaces.Box(floatLow,floatHigh,\n",
    "                                    shape=[self.maxEnemyNum],\n",
    "                                    dtype=np.float32),\n",
    "                'friend_missile': spaces.Box(floatLow,floatHigh,\n",
    "                                             shape=[self.maxFriendMissileNum],\n",
    "                                             dtype=np.float32),\n",
    "                'enemy_missile': spaces.Box(floatLow,floatHigh,\n",
    "                                            shape=[self.maxEnemyMissileNum],\n",
    "                                            dtype=np.float32)\n",
    "            }\n",
    "            obs_space['observation_mask'] = spaces.Dict(observation_mask) # type: ignore\n",
    "\n",
    "        if self.use_action_mask:\n",
    "            single_action_mask_space_dict = {\n",
    "                'turn': spaces.Box(floatLow,floatHigh,\n",
    "                                   shape=[len(self.turnTable)],\n",
    "                                   dtype=np.float32),\n",
    "                'accel': spaces.Box(floatLow,floatHigh,\n",
    "                                    shape=[len(self.accelTable)],\n",
    "                                    dtype=np.float32),\n",
    "                'target': spaces.Box(floatLow,floatHigh,\n",
    "                                     shape=[1+self.maxEnemyNum],\n",
    "                                     dtype=np.float32)\n",
    "            }\n",
    "            single_action_mask_space=spaces.Dict(single_action_mask_space_dict) # type: ignore\n",
    "            action_mask_space_list=[]\n",
    "            for port, parent in self.parents.items():\n",
    "                action_mask_space_list.append(single_action_mask_space)\n",
    "            obs_space['action_mask'] = spaces.Tuple(action_mask_space_list) # type: ignore\n",
    "\n",
    "        return spaces.Dict(obs_space) # type: ignore\n",
    "\n",
    "\n",
    "    def action_space(self):\n",
    "        single_action_space_dict={\n",
    "            'turn': spaces.Discrete(len(self.turnTable)),\n",
    "            'target': spaces.Discrete(1+self.maxEnemyNum),\n",
    "            'accel': spaces.Discrete(len(self.accelTable))\n",
    "        }\n",
    "        single_action_space=spaces.Dict(single_action_space_dict) # type: ignore\n",
    "        action_space_list=[]\n",
    "        for port, parent in self.parents.items():\n",
    "            action_space_list.append(single_action_space)\n",
    "        return spaces.Tuple(action_space_list) # 行動空間の定義\n",
    "\n",
    "\n",
    "    def deploy(self, action):\n",
    "        #observablesの収集\n",
    "        #味方機(parents→parents以外の順)\n",
    "        self.ourMotion=[]\n",
    "        self.ourObservables=[]\n",
    "        firstAlive=None\n",
    "        for port,parent in self.parents.items():\n",
    "            if parent.isAlive():\n",
    "                firstAlive=parent\n",
    "                break\n",
    "\n",
    "        parentFullNames=set()\n",
    "        # まずはparents\n",
    "        for port, parent in self.parents.items():\n",
    "            parentFullNames.add(parent.getFullName())\n",
    "            if parent.isAlive():\n",
    "                self.ourMotion.append(MotionState(parent.observables[\"motion\"]).transformTo(self.getLocalCRS()))\n",
    "                #残存していればobservablesそのもの\n",
    "                self.ourObservables.append(parent.observables)\n",
    "            else:\n",
    "                self.ourMotion.append(MotionState())\n",
    "                #被撃墜or墜落済なら本体の更新は止まっているので残存している親が代理更新したものを取得(誘導弾情報のため)\n",
    "                self.ourObservables.append(\n",
    "                    firstAlive.observables.at_p(\"/shared/fighter\").at(parent.getFullName()))\n",
    "\n",
    "        # その後にparents以外\n",
    "        for fullName,fObs in firstAlive.observables.at_p(\"/shared/fighter\").items():\n",
    "            if not fullName in parentFullNames:\n",
    "                if fObs.at(\"isAlive\"):\n",
    "                    self.ourMotion.append(MotionState(fObs[\"motion\"]).transformTo(self.getLocalCRS()))\n",
    "                else:\n",
    "                    self.ourMotion.append(MotionState())\n",
    "\n",
    "                self.ourObservables.append(fObs)\n",
    "\n",
    "\n",
    "        # 彼機情報だけは射撃対象の選択と連動するので更新してはいけない。\n",
    "        #味方誘導弾(射撃時刻の古い順にソート)\n",
    "        def launchedT(m):\n",
    "            return Time(m[\"launchedT\"]) if m[\"isAlive\"] and m[\"hasLaunched\"] else Time(np.inf,TimeSystem.TT)\n",
    "        self.msls=sorted(sum([[m for m in f.at_p(\"/weapon/missiles\")] for f in self.ourObservables],[]),key=launchedT)\n",
    "\n",
    "        #彼側誘導弾(各機の正面に近い順にソート)\n",
    "        self.mws=[]\n",
    "        for fIdx,fMotion in enumerate(self.ourMotion):\n",
    "            fObs=self.ourObservables[fIdx]\n",
    "            self.mws.append([])\n",
    "            if fObs[\"isAlive\"]:\n",
    "                if fObs.contains_p(\"/sensor/mws/track\"):\n",
    "                    for mObs in fObs.at_p(\"/sensor/mws/track\"):\n",
    "                        self.mws[fIdx].append(Track2D(mObs).transformTo(self.getLocalCRS()))\n",
    "                sortTrack2DByAngle(self.mws[fIdx],fMotion,np.array([1,0,0]),True)\n",
    "\n",
    "        for pIdx,parent in enumerate(self.parents.values()):\n",
    "            parentFullName=parent.getFullName()\n",
    "            if not parent.isAlive():\n",
    "                continue\n",
    "            actionInfo=self.actionInfos[parentFullName]\n",
    "            myMotion=self.ourMotion[pIdx]\n",
    "            myObs=self.ourObservables[pIdx]\n",
    "            myMWS=self.mws[pIdx]\n",
    "            myAction=action[pIdx]\n",
    "\n",
    "            #左右旋回\n",
    "            deltaAz=self.turnTable[myAction[\"turn\"]]\n",
    "            actionInfo.dstDir=self.teamOrigin.relBtoP(np.array([cos(deltaAz),sin(deltaAz),0]))\n",
    "            dstAz=atan2(actionInfo.dstDir[1],actionInfo.dstDir[0])\n",
    "\n",
    "            #上昇・下降\n",
    "            dstPitch=0\n",
    "            actionInfo.dstDir=np.array([actionInfo.dstDir[0]*cos(dstPitch),actionInfo.dstDir[1]*cos(dstPitch),-sin(dstPitch)])\n",
    "\n",
    "            #加減速\n",
    "            V=np.linalg.norm(myMotion.vel())\n",
    "            actionInfo.asThrottle=False\n",
    "            accel=self.accelTable[myAction[\"accel\"]]\n",
    "            actionInfo.dstV=V+accel\n",
    "            actionInfo.keepVel = accel==0.0\n",
    "\n",
    "            #下限速度の制限\n",
    "            if V<self.minimumV:\n",
    "                actionInfo.velRecovery=True\n",
    "            if V>=self.minimumRecoveryV:\n",
    "                actionInfo.velRecovery=False\n",
    "            if actionInfo.velRecovery:\n",
    "                actionInfo.dstV=self.minimumRecoveryDstV\n",
    "                actionInfo.asThrottle=False\n",
    "\n",
    "            #射撃\n",
    "            #actionのパース\n",
    "            shotTarget=myAction[\"target\"]-1\n",
    "\n",
    "            #射撃可否の判断、射撃コマンドの生成\n",
    "            flyingMsls=0\n",
    "            if myObs.contains_p(\"/weapon/missiles\"):\n",
    "                for msl in myObs.at_p(\"/weapon/missiles\"):\n",
    "                    if msl.at(\"isAlive\")() and msl.at(\"hasLaunched\")():\n",
    "                        flyingMsls+=1\n",
    "            if not (\n",
    "                shotTarget>=0 and\n",
    "                shotTarget<len(self.lastTrackInfo) and\n",
    "                parent.isLaunchableAt(self.lastTrackInfo[shotTarget]) and\n",
    "                flyingMsls<self.maxSimulShot\n",
    "            ):\n",
    "                shotTarget=-1\n",
    "            if shotTarget>=0:\n",
    "                actionInfo.launchFlag=True\n",
    "                actionInfo.target=self.lastTrackInfo[shotTarget]\n",
    "            else:\n",
    "                actionInfo.launchFlag=False\n",
    "                actionInfo.target=Track3D()\n",
    "\n",
    "            self.observables[parentFullName][\"decision\"]={\n",
    "                \"Roll\":(\"Don't care\"),\n",
    "                \"Fire\":(actionInfo.launchFlag,actionInfo.target.to_json())\n",
    "            }\n",
    "            if len(myMWS)>0 and self.use_override_evasion:\n",
    "                self.observables[parentFullName][\"decision\"][\"Horizontal\"]=(\"Az_NED\",dstAz)\n",
    "            else:\n",
    "                if self.dstAz_relative:\n",
    "                    self.observables[parentFullName][\"decision\"][\"Horizontal\"]=(\"Az_BODY\",deltaAz)\n",
    "                else:\n",
    "                    self.observables[parentFullName][\"decision\"][\"Horizontal\"]=(\"Az_NED\",dstAz)\n",
    "            self.observables[parentFullName][\"decision\"][\"Vertical\"]=(\"El\",dstPitch)\n",
    "            if actionInfo.asThrottle:\n",
    "                self.observables[parentFullName][\"decision\"][\"Throttle\"]=(\"Throttle\",actionInfo.dstThrottle)\n",
    "            else:\n",
    "                self.observables[parentFullName][\"decision\"][\"Throttle\"]=(\"Vel\",actionInfo.dstV)\n",
    "\n",
    "\n",
    "    def control(self):\n",
    "        #observablesの収集\n",
    "        #味方機(parents→parents以外の順)\n",
    "        self.ourMotion=[]\n",
    "        self.ourObservables=[]\n",
    "        firstAlive=None\n",
    "        for port,parent in self.parents.items():\n",
    "            if parent.isAlive():\n",
    "                firstAlive=parent\n",
    "                break\n",
    "\n",
    "        parentFullNames=set()\n",
    "        # まずはparents\n",
    "        for port, parent in self.parents.items():\n",
    "            parentFullNames.add(parent.getFullName())\n",
    "            if parent.isAlive():\n",
    "                self.ourMotion.append(MotionState(parent.observables[\"motion\"]).transformTo(self.getLocalCRS()))\n",
    "                #残存していればobservablesそのもの\n",
    "                self.ourObservables.append(parent.observables)\n",
    "            else:\n",
    "                self.ourMotion.append(MotionState())\n",
    "                #被撃墜or墜落済なら本体の更新は止まっているので残存している親が代理更新したものを取得(誘導弾情報のため)\n",
    "                self.ourObservables.append(\n",
    "                    firstAlive.observables.at_p(\"/shared/fighter\").at(parent.getFullName()))\n",
    "\n",
    "        # その後にparents以外\n",
    "        for fullName,fObs in firstAlive.observables.at_p(\"/shared/fighter\").items():\n",
    "            if not fullName in parentFullNames:\n",
    "                if fObs.at(\"isAlive\"):\n",
    "                    self.ourMotion.append(MotionState(fObs[\"motion\"]).transformTo(self.getLocalCRS()))\n",
    "                else:\n",
    "                    self.ourMotion.append(MotionState())\n",
    "\n",
    "                self.ourObservables.append(fObs)\n",
    "\n",
    "\n",
    "        # 彼機情報だけは射撃対象の選択と連動するので更新してはいけない。\n",
    "        #味方誘導弾(射撃時刻の古い順にソート)\n",
    "        def launchedT(m):\n",
    "            return Time(m[\"launchedT\"]) if m[\"isAlive\"] and m[\"hasLaunched\"] else Time(np.inf,TimeSystem.TT)\n",
    "        self.msls=sorted(sum([[m for m in f.at_p(\"/weapon/missiles\")] for f in self.ourObservables],[]),key=launchedT)\n",
    "\n",
    "        #彼側誘導弾(各機の正面に近い順にソート)\n",
    "        self.mws=[]\n",
    "        for fIdx,fMotion in enumerate(self.ourMotion):\n",
    "            fObs=self.ourObservables[fIdx]\n",
    "            self.mws.append([])\n",
    "            if fObs[\"isAlive\"]:\n",
    "                if fObs.contains_p(\"/sensor/mws/track\"):\n",
    "                    for mObs in fObs.at_p(\"/sensor/mws/track\"):\n",
    "                        self.mws[fIdx].append(Track2D(mObs).transformTo(self.getLocalCRS()))\n",
    "                sortTrack2DByAngle(self.mws[fIdx],fMotion,np.array([1,0,0]),True)\n",
    "\n",
    "        #Setup collision avoider\n",
    "        avoider=StaticCollisionAvoider2D()\n",
    "        #北側\n",
    "        c={\n",
    "            \"p1\":np.array([+self.dOut,-5*self.dLine,0]),\n",
    "            \"p2\":np.array([+self.dOut,+5*self.dLine,0]),\n",
    "            \"infinite_p1\":True,\n",
    "            \"infinite_p2\":True,\n",
    "            \"isOneSide\":True,\n",
    "            \"inner\":np.array([0.0,0.0]),\n",
    "            \"limit\":self.dOutLimit,\n",
    "            \"threshold\":self.dOutLimitThreshold,\n",
    "            \"adjustStrength\":self.dOutLimitStrength,\n",
    "        }\n",
    "        avoider.borders.append(LinearSegment(c))\n",
    "        #南側\n",
    "        c={\n",
    "            \"p1\":np.array([-self.dOut,-5*self.dLine,0]),\n",
    "            \"p2\":np.array([-self.dOut,+5*self.dLine,0]),\n",
    "            \"infinite_p1\":True,\n",
    "            \"infinite_p2\":True,\n",
    "            \"isOneSide\":True,\n",
    "            \"inner\":np.array([0.0,0.0]),\n",
    "            \"limit\":self.dOutLimit,\n",
    "            \"threshold\":self.dOutLimitThreshold,\n",
    "            \"adjustStrength\":self.dOutLimitStrength,\n",
    "        }\n",
    "        avoider.borders.append(LinearSegment(c))\n",
    "        #東側\n",
    "        c={\n",
    "            \"p1\":np.array([-5*self.dOut,+self.dLine,0]),\n",
    "            \"p2\":np.array([+5*self.dOut,+self.dLine,0]),\n",
    "            \"infinite_p1\":True,\n",
    "            \"infinite_p2\":True,\n",
    "            \"isOneSide\":True,\n",
    "            \"inner\":np.array([0.0,0.0]),\n",
    "            \"limit\":self.dOutLimit,\n",
    "            \"threshold\":self.dOutLimitThreshold,\n",
    "            \"adjustStrength\":self.dOutLimitStrength,\n",
    "        }\n",
    "        avoider.borders.append(LinearSegment(c))\n",
    "        #西側\n",
    "        c={\n",
    "            \"p1\":np.array([-5*self.dOut,-self.dLine,0]),\n",
    "            \"p2\":np.array([+5*self.dOut,-self.dLine,0]),\n",
    "            \"infinite_p1\":True,\n",
    "            \"infinite_p2\":True,\n",
    "            \"isOneSide\":True,\n",
    "            \"inner\":np.array([0.0,0.0]),\n",
    "            \"limit\":self.dOutLimit,\n",
    "            \"threshold\":self.dOutLimitThreshold,\n",
    "            \"adjustStrength\":self.dOutLimitStrength,\n",
    "        }\n",
    "        avoider.borders.append(LinearSegment(c))\n",
    "        for pIdx,parent in enumerate(self.parents.values()):\n",
    "            parentFullName=parent.getFullName()\n",
    "            if not parent.isAlive():\n",
    "                continue\n",
    "            actionInfo=self.actionInfos[parentFullName]\n",
    "            myMotion=self.ourMotion[pIdx]\n",
    "            myObs=self.ourObservables[pIdx]\n",
    "            originalMyMotion=MotionState(myObs[\"motion\"]) #機体側にコマンドを送る際には元のparent座標系での値が必要\n",
    "\n",
    "            #戦域逸脱を避けるための方位補正\n",
    "            actionInfo.dstDir=avoider(myMotion,actionInfo.dstDir)\n",
    "\n",
    "            #高度方向の補正\n",
    "            n=sqrt(actionInfo.dstDir[0]*actionInfo.dstDir[0]+actionInfo.dstDir[1]*actionInfo.dstDir[1])\n",
    "            dstPitch=atan2(-actionInfo.dstDir[2],n)\n",
    "            #高度下限側\n",
    "            bottom=self.altitudeKeeper(myMotion,actionInfo.dstDir,self.altMin)\n",
    "            minPitch=atan2(-bottom[2],sqrt(bottom[0]*bottom[0]+bottom[1]*bottom[1]))\n",
    "            #高度上限側\n",
    "            top=self.altitudeKeeper(myMotion,actionInfo.dstDir,self.altMax)\n",
    "            maxPitch=atan2(-top[2],sqrt(top[0]*top[0]+top[1]*top[1]))\n",
    "            dstPitch=max(minPitch,min(maxPitch,dstPitch))\n",
    "            cs=cos(dstPitch)\n",
    "            sn=sin(dstPitch)\n",
    "            actionInfo.dstDir=np.array([actionInfo.dstDir[0]/n*cs,actionInfo.dstDir[1]/n*cs,-sn])\n",
    "\n",
    "            self.commands[parentFullName]={\n",
    "                \"motion\":{\n",
    "                    \"dstDir\":originalMyMotion.dirAtoP(actionInfo.dstDir,myMotion.pos(),self.getLocalCRS()) #元のparent座標系に戻す\n",
    "                },\n",
    "                \"weapon\":{\n",
    "                    \"launch\":actionInfo.launchFlag,\n",
    "                    \"target\":actionInfo.target.to_json()\n",
    "                }\n",
    "            }\n",
    "            if actionInfo.asThrottle:\n",
    "                self.commands[parentFullName][\"motion\"][\"dstThrottle\"]=actionInfo.dstThrottle\n",
    "            elif actionInfo.keepVel:\n",
    "                self.commands[parentFullName][\"motion\"][\"dstAccel\"]=0.0\n",
    "            else:\n",
    "                self.commands[parentFullName][\"motion\"][\"dstV\"]=actionInfo.dstV\n",
    "            actionInfo.launchFlag=False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## policyの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policyモデルを導入する前に事前に定義した行動の出力を確認したいとき"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[エージェントの作成](#エージェントの作成)で実装した行動空間の出力を確認したいときは`policy`メソッドで渡される`action_space`で適当にサンプリングしてみるとよい.\n",
    "\n",
    "例えば下記のように`__init__.py`の中でDummyPolicyを定義してその中でサンプリングする処理を実装する.\n",
    "\n",
    "```Python\n",
    "class DummyPolicy(StandalonePolicy):\n",
    "    def step(self,observation,reward,done,info,agentFullName,observation_space,action_space):\n",
    "        actions = action_space.sample()\n",
    "        b = []\n",
    "        for a in actions:\n",
    "            d = {k: int(v) for k, v in a.items()}\n",
    "            b.append(d)\n",
    "        print(b)\n",
    "        return b\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policyモデルの定義"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "observationを渡してactionを返すpolicyモデルを実装する. ここでは`R7ContestSample.R7ContestTorchNNSampleForHandyRL.R7ContestTorchNNSampleForHandyRL`により深層学習モデルを構築する前提とする. \n",
    "\n",
    "コンフィグファイル`sample_config.yml`の`policy_config`->`Learner`->`model_config`を適宜編集して深層学習モデルを新たに定義することができる.\n",
    "\n",
    "```Yaml\n",
    "actionDistributionClassGetter: actionDistributionClassGetter\n",
    "use_lstm: false\n",
    "lstm_cell_size: 256\n",
    "lstm_num_layers: 1\n",
    "lstm_dropout: 0.2\n",
    "common:\n",
    "    layers:\n",
    "        - [\"Linear\",{\"out_features\": 16}]\n",
    "        - [\"ReLU\",{}]\n",
    "        - [\"ResidualBlock\",{\n",
    "            \"layers\":[\n",
    "                [\"Linear\",{\"out_features\": 16}],\n",
    "                [\"BatchNorm1d\",{}]\n",
    "            ]}]\n",
    "        - [\"ReLU\",{}]\n",
    "        - [\"ResidualBlock\",{\n",
    "            \"layers\":[\n",
    "                [\"Linear\",{\"out_features\": 16}],\n",
    "                [\"BatchNorm1d\",{}]\n",
    "            ]}]\n",
    "parent:\n",
    "    layers:\n",
    "        - [\"Linear\",{\"out_features\": 64}]\n",
    "        - [\"ReLU\",{}]\n",
    "        - [\"ResidualBlock\",{\n",
    "            \"layers\":[\n",
    "                [\"Linear\",{\"out_features\": 64}],\n",
    "                [\"BatchNorm1d\",{}]\n",
    "            ]}]\n",
    "        - [\"ReLU\",{}]\n",
    "        - [\"ResidualBlock\",{\n",
    "            \"layers\":[\n",
    "                [\"Linear\",{\"out_features\": 64}],\n",
    "                [\"BatchNorm1d\",{}]\n",
    "            ]}]\n",
    "...\n",
    "```\n",
    "\"common\", \"parent\"などの`make_obs`メソッドで生成したobservationのキーごとにネットワーク構造を定義できるようになっている.\n",
    "`layers`の中で層を増やしたりノード数を増やしたりして深層学習モデルの構造を新たに定義する. 前に設定した`observation_space`や`action_space`によって入力層や出力層が決まる. \n",
    "\n",
    "対戦を実行する際は強化学習フレームワークから独立させてPolicyを使用するためのインターフェースによりpolicyを作成する(ここでは提供されている`ASRCAISim1.plugins.HandyRLUtility.StandaloneHandyRLPolicy`を使用). importして呼べるようにしておく.\n",
    "\n",
    "[HandyRL(の改変版)を用いた強化学習サンプル/yaml で定義可能なニューラルネットワークのサンプル](http://localhost:5500/docs/html/core/a198026.html#section_r7_contest_handyrl_sample_nn)も参照されたい.\n",
    "\n",
    "\n",
    "強化学習を前提としない場合は投稿プログラム内で適当な値を返すダミーpolicyを実装しておく."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, yaml\n",
    "from R7ContestSample.R7ContestTorchNNSampleForHandyRL import R7ContestTorchNNSampleForHandyRL\n",
    "from ASRCAISim1.plugins.HandyRLUtility.StandaloneHandyRLPolicy import StandaloneHandyRLPolicy # type: ignore\n",
    "from ASRCAISim1.plugins.HandyRLUtility.distribution import getActionDistributionClass # type: ignore\n",
    "\n",
    "model_config=yaml.safe_load(open(os.path.join(os.path.dirname(__file__),\"model_config.yaml\"),\"r\"))\n",
    "weightPath = None\n",
    "isDeterministic=False #決定論的に行動させたい場合はTrue、確率論的に行動させたい場合はFalseとする\n",
    "policy = StandaloneHandyRLPolicy(R7ContestTorchNNSampleForHandyRL,model_config,weightPath,getActionDistributionClass,isDeterministic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 独自のPolicyモデルを使用したいとき"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`R7ContestTorchNNSampleForHandyRL`以外の独自のPolicyモデルを実装したい場合は, どこかにモデルを定義したpyファイルを用意して`main.py`でimportして`custom_classes`の中に登録しておき, `sample_config.yml`の中の`policy_config`->`Learner`->`model_class`の中に対応するkeyを記載すればよい. 以下は実装したモデルが`MyPolicyModel`だった場合の例.\n",
    "\n",
    "```Python\n",
    "from policy_model import MyPolicyModel\n",
    "\n",
    "custom_classes={\n",
    "    # models\n",
    "    \"R7ContestTorchNNSampleForHandyRL\": R7ContestTorchNNSampleForHandyRL,\n",
    "    \"DummyInternalModel\": DummyInternalModel,\n",
    "    \"MyPolicyModel\": MyPolicyModel,\n",
    "    # match maker\n",
    "    \"R7ContestTwoTeamCombatMatchMaker\": R7ContestTwoTeamCombatMatchMaker,\n",
    "    \"TwoTeamCombatMatchMonitor\": TwoTeamCombatMatchMonitor,\n",
    "    # action distribution class getter\n",
    "    \"actionDistributionClassGetter\": getActionDistributionClass,\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "[HandyRL(の改変版)を用いた強化学習サンプル/カスタムクラスの使用](http://localhost:5500/docs/html/core/a198026.html#section_r7_contest_handyrl_sample_custom_classes)も参照されたい."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Factoryへの追加"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 独自のAgentの登録"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習を実行するときに作成したエージェントを呼べるように登録しておく必要がある.\n",
    "\n",
    "`./sample_config.yml`の\"env_args\"->\"env\"の値で実際に環境構築を行うモジュールを選択している(デフォルトでは`sample`という名前になっていて, `handyrl.envs.SampleEnv.sample.py`が利用されることになる.)が, シミュレーション環境構築時(`handyrl.envs.SampleEnv.sample.py`のL33-54の部分)でエージェントの登録を行っている.\n",
    "\n",
    "```Python\n",
    "# エージェントの登録\n",
    "userModelID=args[\"userModelID\"]\n",
    "userModuleID=args[\"userModuleID\"]\n",
    "with open(os.path.join(userModuleID, args[\"modelargs\"])) as f:\n",
    "    model_args = json.load(f)\n",
    "\n",
    "module = importlib.import_module(userModuleID)\n",
    "assert hasattr(module, \"getUserAgentClass\")\n",
    "assert hasattr(module, \"getUserAgentModelConfig\")\n",
    "assert hasattr(module, \"isUserAgentSingleAsset\")\n",
    "assert hasattr(module, \"getUserPolicy\")\n",
    "\n",
    "agentClass = module.getUserAgentClass(model_args)\n",
    "addPythonClass(\"Agent\", \"Agent_\"+userModelID, agentClass)\n",
    "Factory.addDefaultModel(\n",
    "    \"Agent\",\n",
    "    \"Agent_\"+userModelID,\n",
    "    {\n",
    "        \"class\": \"Agent_\"+userModelID,\n",
    "        \"config\": module.getUserAgentModelConfig(model_args)\n",
    "    }\n",
    ")\n",
    "```\n",
    "\n",
    "`userModuleID`という名前のディレクトリに`__init__.py`があって, インポートしている. デフォルトでは`Test`という名前としている(`./Test`以下を実際に確認されたい.).\n",
    "\n",
    "`./sample_config.yml`の\"env_args\"の\"userModelID\"の値`userModelID`が`Agent_{userModelID}`という形でクラス名として登録される. この名前と`R7_contest_learning_config_{M,S}.json`の\"AgentConfigDispatcher\"に記載の\"Learner_e\"の\"model\"の値を一致させることで作成したエージェントによる学習が実行可能となる(デフォルトでは\"userModelID\"は`Sample`としているので`Agent_Sample`としている. 各自確認されたい.).\n",
    "\n",
    "ここでは特に扱っていないが, 並列実行する場合は全てのインスタンス上でFactoryへの追加が行われる必要がある(EnvironmentはWorkerごとにインスタンス化される(__init__がWorkerごとに呼ばれる)ため, 全てのインスタンスでFactoryへのモデル追加が独立に行われる).\n",
    "\n",
    "デフォルトでは中央集権型として扱うため`R7_contest_learning_config_M.json`を自作エージェントに合わせるように編集している.\n",
    "\n",
    "エージェント登録の別の方法として, R7ContestSampleに独自のクラスを作成しておいて(ビルドして`site-packages`を更新)`configs/R7_contest_agent_ruler_reward_models.json`で\"Factory\"の\"Agent\"項目で好きな名前(`新エージェント名`とする)を登録して, その\"class\"において, 作成した独自のクラス名を記載しておくことも可能. その際は\"AgentConfigDispatcher\"に記載の\"Learner_e\"の\"model\"の値を`新エージェント名`にする.\n",
    "\n",
    "投稿可能なプログラムを作成するときはクラスを記述する部分を別のpyファイルとして作成してインポートできるようにしたり, `__init__.py`に直接書き込んでその中で呼べるようにしておく必要がある. 以下は`__init__.py`に直接書き込む場合の例.\n",
    "\n",
    "```Python\n",
    "def getUserAgentClass(args={}):\n",
    "    import 独自のクラス名\n",
    "    return 独自のクラス名\n",
    "\n",
    "class 独自のクラス名():\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 独自のRewardの登録\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "シミュレーション環境構築時(`handyrl.envs.SampleEnv.sample.py`のL56-72の部分)で報酬の登録を行っている.\n",
    "\n",
    "```Python\n",
    "# 報酬の登録\n",
    "userRewardModuleID = args[\"userRewardModuleID\"]\n",
    "with open(args[\"rewardConfig\"]) as f:\n",
    "    reward_config = json.load(f)\n",
    "\n",
    "reward_module = importlib.import_module(userRewardModuleID)\n",
    "\n",
    "rewardClass = reward_module.MyReward\n",
    "addPythonClass(\"Reward\", userRewardModuleID, rewardClass)\n",
    "Factory.addDefaultModel(\n",
    "    \"Reward\",\n",
    "    userRewardModuleID,\n",
    "    {\n",
    "        \"class\": \"MyReward\",\n",
    "        \"config\": reward_config\n",
    "    }\n",
    ")\n",
    "```\n",
    "\n",
    "`MyReward.py`の`MyReward`モジュールを読み込んで`reward_config.json`で記述されている設定ファイルを渡して登録をしている. この実装ではクラス名は`MyReward`で固定する必要がある. `MyReward.py`では, `onInnerStepEnd`メソッドにおいてインナーステップ終了時に残存機数に応じて報酬を与えるシンプルなものとなっている. 適宜改修されたい. また, [独自 Reward の実装方法](http://localhost:5500/docs/html/core/a198019.html)も参照されたい. `R7ContestSample`にも`R7ContestPyRewardSample01.py`などに報酬の実装例があるため, こちらも参照すること.\n",
    "\n",
    "またエージェントの場合と同様に, R7ContestSampleに独自のクラスを作成しておいて(ビルドして`site-packages`を更新)`configs/R7_contest_agent_ruler_reward_models.json`で\"Factory\"の\"Reward\"項目で好きな名前(`新報酬名`とする)を登録して, その\"class\"において, 作成した独自のクラス名を記載しておくことも可能.\n",
    "\n",
    "学習設定ファイル`configs/R7_contest_learning_config_{M/S}.json`の\"Reward\"で登録する報酬を以下のようにリストで渡すとその合計値を実際の報酬として返す. ここで実装している`MyReward.py`を報酬として学習させたい場合, `sample_config.yml`の\"env_args\"の\"userRewardModuleID\"の値を以下のように\"model\"の値として記述しておく. \"target\"を以下のように\"All\"とすると場に存在する者すべての陣営及びAgentが計算対象となる.\n",
    "\n",
    "```json\n",
    "[\n",
    "    {\"model\":\"MyReward\",\"target\":\"All\"},\n",
    "    {\"model\":\"MyWinLoseReward\",\"target\":\"All\"}\n",
    "]\n",
    "```\n",
    "\n",
    "以下は`MyReward.py`の実装例."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ASRCAISim1.core import TeamReward, nljson, Fighter\n",
    "\n",
    "\n",
    "class MyReward(TeamReward):\n",
    "    \"\"\"\n",
    "    チーム全体で共有する報酬は TeamReward を継承し、\n",
    "    個別の Agent に与える報酬は AgentReward を継承する。\n",
    "    \"\"\"\n",
    "    def __init__(self, modelConfig: nljson, instanceConfig: nljson):\n",
    "        super().__init__(modelConfig, instanceConfig)\n",
    "        if(self.isDummy):\n",
    "            return #Factory によるダミー生成のために空引数でのインスタンス化に対応させる\n",
    "\n",
    "\n",
    "    def onEpisodeBegin(self):\n",
    "        \"\"\"\n",
    "        エピソード開始時の処理(必要に応じてオーバーライド)\n",
    "        基底クラスにおいて config に基づき報酬計算対象の設定等が行われるため、\n",
    "        それ以外の追加処理や設定の上書きを行いたい場合のみオーバーライドする。\n",
    "        \"\"\"\n",
    "        super().onEpisodeBegin()\n",
    "\n",
    "\n",
    "    def onStepBegin(self):\n",
    "        \"\"\"\n",
    "        step 開始時の処理(必要に応じてオーバーライド)\n",
    "        基底クラスにおいて reward(step 報酬)を 0 にリセットしているため、\n",
    "        オーバーライドする場合、基底クラスの処理を呼び出すか、同等の処理が必要。\n",
    "        \"\"\"\n",
    "        super().onEpisodeBegin()\n",
    "    \n",
    "    \n",
    "    def onInnerStepBegin(self):\n",
    "        \"\"\"\n",
    "        インナーステップ開始時の処理(必要に応じてオーバーライド)\n",
    "        デフォルトでは何も行わないが、より細かい報酬計算が必要な場合に使用可能。\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def onInnerStepEnd(self):\n",
    "        \"\"\"\n",
    "        インナーステップ終了時の処理(必要に応じてオーバーライド)\n",
    "        一定周期で呼び出されるため、極力この関数で計算する方が望ましい。\n",
    "        \"\"\"\n",
    "        for team in self.reward: # team に属している Asset(Fighter)を取得する例\n",
    "            for f in self.manager.getAssets(lambda a:a.getTeam()==team and isinstance(a,Fighter)):\n",
    "                if(f().isAlive()):\n",
    "                    self.reward[team] += 0.1 #例えば、残存数に応じて報酬を与える場合\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 学習の実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作成したエージェントを学習する. 学習に使用する環境やモデルや学習条件などが`./sample_config.yml`として与えられている. 特に\"env_args\"の\"userModuleID\"と\"model_args\"にはそれぞれ実装したエージェント(`MyAgent.py`)が保存されるディレクトリ(デフォルトでは`Test`)とその引数ファイル(`args.json`)を設定する(`./sample_config.yml`参照). その他設定などについては[HandyRL(の改変版)を用いた強化学習サンプル/yaml の記述方法](http://localhost:5500/docs/html/core/a198026.html#section_r7_contest_handyrl_sample_yaml_format)を参照されたい. なお, `./sample_config.yml`ではオープン部門用(中央集権方式)の設定としている.\n",
    "\n",
    "\n",
    "例えば学習条件としてエポック数を変えたい場合は`sample_config.yml`の`train_args`->`Learner`で`epochs`を変えればよい(-1に設定すると上限なしとなる.).\n",
    "\n",
    "```Yaml\n",
    "train_args:\n",
    "    Learner:\n",
    "...\n",
    "        epochs: 5 # エポック数を5にしたい場合\n",
    "```\n",
    "\n",
    "詳細は[HandyRL(の改変版)を用いた強化学習サンプル/yaml の記述方法](http://localhost:5500/docs/html/core/a198026.html#section_r7_contest_handyrl_sample_yaml_format)を参照されたい\n",
    "\n",
    "エージェント(`MyAgent.py`)とその引数ファイル(`args.json`), エージェントに対する設定ファイル(`agent_config.json`)を`./Test`以下に格納しておく. すると`./Test`は以下のようなディレクトリ構造になる.\n",
    "\n",
    "```bash\n",
    "Test\n",
    "├─ __init__.py\n",
    "├─ agent_config.json\n",
    "├─ args.json\n",
    "└─ MyAgent.py\n",
    "```\n",
    "\n",
    "そして以下のコマンドを実行する."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /path/to/tutorialで実行\n",
    "!python main.py sample_config.yml --train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習済みモデルは`./results/Open/Multi/YYYYmmddHHMMSS/policies/checkpoints`以下に保存される(pthファイル)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 投稿可能なプログラム一式としてまとめる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習済みモデル(例えば`Learner-latest.pth`)を`./Test`以下に格納する. `args.json`の\"weightPath\"の値を`Learner-latest.pth`としておく. また, 学習時に使用したモデルの設定ファイルと同等のものとして`model_config.yaml`を格納する(`sample_config.yml`の\"policy_config\"などの内容と整合することを確認しておく.). そして最終的に以下のようなディレクトリ構造となることを確認.\n",
    "\n",
    "```bash\n",
    "Test\n",
    "├─ __init__.py\n",
    "├─ agent_config.json\n",
    "├─ args.json\n",
    "├─ Learner-latest.pth\n",
    "├─ model_config.yaml\n",
    "└─ MyAgent.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 対戦を実行する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作成したエージェントをサンプルルールベースモデルと戦わせる. デフォルトではオープン部門の条件(`--youth`が0)で`./Test`で作ったエージェントモジュールと`./BenchMark`で与えられるサンプルルールベースモデルの対戦となる."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /path/to/tutorialで実行\n",
    "!python validate.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "適宜`--color`を\"Blue\"や\"Red\"に変えて陣営の種類に応じた行動が取れているかなどを確認する(実際の対戦では陣営の色はランダムに決まる). また, `--replay`や`--visualize`を`1`にして実際にどのように動いているかを確認するなりログを参考にしてobservationの作成方法に工夫を施したり`sample_config.yml`で使用するモデルを変えたり学習の仕方に工夫を施すなどしてアルゴリズムをよりよくする."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 応募用ファイルを作成する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作成したプログラムをzipファイルとして圧縮する."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /path/to/tutorialで実行\n",
    "!zip -r submit ./Test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
